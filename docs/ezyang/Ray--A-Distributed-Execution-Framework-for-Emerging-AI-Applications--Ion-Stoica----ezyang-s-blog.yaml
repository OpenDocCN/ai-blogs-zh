- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-07-01 18:16:59'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-07-01 18:16:59'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Ray: A Distributed Execution Framework for Emerging AI Applications (Ion Stoica)
    : ezyang’s blog'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ray：一个用于新兴AI应用的分布式执行框架（Ion Stoica）：ezyang's blog
- en: 来源：[http://blog.ezyang.com/2017/12/ray-a-distributed-execution-framework-for-emerging-ai-applications-ion-stoica/](http://blog.ezyang.com/2017/12/ray-a-distributed-execution-framework-for-emerging-ai-applications-ion-stoica/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[http://blog.ezyang.com/2017/12/ray-a-distributed-execution-framework-for-emerging-ai-applications-ion-stoica/](http://blog.ezyang.com/2017/12/ray-a-distributed-execution-framework-for-emerging-ai-applications-ion-stoica/)
- en: The below is a transcript of a talk by [Ion Stoica](https://people.eecs.berkeley.edu/~istoica/)
    on [Ray](https://github.com/ray-project/ray), at the [ML Systems Workshop](https://nips.cc/Conferences/2017/Schedule?showEvent=8774)
    at NIPS'17.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是[Ion Stoica](https://people.eecs.berkeley.edu/~istoica/)在[NIPS'17的ML系统研讨会](https://nips.cc/Conferences/2017/Schedule?showEvent=8774)上关于[Ray](https://github.com/ray-project/ray)的讲话的记录。
- en: '* * *'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We've been working on it at Berkeley for more than one year. Over the past years,
    there's been tremendous progress in AI. Ad targeting, image&speech, many more.
    Many applications are based on supervised learning with DNNs. Supervised plus
    unsupervised are the two dominant approaches.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在伯克利已经研究了一年多了。在过去的几年里，AI取得了巨大的进步。广告定向、图像和语音等领域都有显著的发展。许多应用都基于使用深度神经网络的监督学习。监督学习和无监督学习是两种主要的方法。
- en: However, the next generation of AI applications will be very different. They're
    deployed in mission critical scenarios, need to continually learn from a rapidly
    changing env. Robotics, self driving cars, unmanned drones, dialogue systems.
    Implementing this new generation of AI applications requires a broader range of
    techniques. Stochastic optimization, parallel simulations, many more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，下一代AI应用程序将会非常不同。它们部署在关键任务场景中，需要不断地从快速变化的环境中学习。机器人技术、自动驾驶汽车、无人机、对话系统等。实现这一新一代AI应用程序需要更广泛的技术应用。随机优化、并行模拟等等。
- en: 'Ray provides a unified platform for implementing these approaches. To motivate
    Ray, I''ll use reinforcement learning. RL learns by interacting with env. A policy
    mapping from state/observation to action that maximizes a certain reward. What
    are the reqs of RL? Many applications exhibit nested parallelism: search, where
    they use data parallel SGD, which then calls a component that does policy evaluation
    with a model to simulate, that runs in parallel on multiple CPUs. Second, these
    workloads can be highly heterogenous in hardware and time. Many of these computations
    require not only CPUs, but GPUs TPUs and FPGAs. Second, this computation can take
    wildly different times. Simulate a chess game: 3 moves to lose, or 50 moves to
    win or draw. And in robotics, we need to process in real time, processing the
    data from sensors in parallel, tens of ms.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Ray为实施这些方法提供了一个统一的平台。为了激励Ray，我将使用强化学习。RL通过与环境交互进行学习。策略将状态/观察映射到行动，以最大化某种奖励。RL的需求是什么？许多应用程序表现出嵌套并行性：搜索中使用数据并行SGD，然后调用一个组件进行模拟策略评估，这在多个CPU上并行运行。其次，这些工作负载在硬件和时间上高度异构。许多计算不仅需要CPU，还需要GPU、TPU和FPGA。其次，这些计算可能需要非常不同的时间。模拟棋盘游戏：3步输掉，或者50步赢或平局。在机器人技术中，我们需要实时处理，同时并行处理来自传感器的数据，处理时间在十几毫秒之内。
- en: 'Meeting these requirements is not easy. To meet these requirements, you need
    a system that is flexible and performant. Flexible: it should create and schedule
    tasks dynamically, and support arbitrary dependencies. Perf: it should scale to
    hundreds of nodes, sub-millisecond latency, millions of task, and efficiently
    share numeric data.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 满足这些要求并不容易。为了达到这些要求，您需要一个灵活和高性能的系统。灵活性：它应该能够动态创建和调度任务，并支持任意的依赖关系。性能：它应该能够扩展到数百个节点，毫秒级延迟，数百万个任务，并能高效地共享数值数据。
- en: 'Next, I''m going to say how we achieve these challenges. Flexibility? We provide
    a very flexible model: dynamic tasks graphs. On top of this, we give the two models:
    parallel tasks and actors.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将说明我们如何应对这些挑战。灵活性？我们提供一个非常灵活的模型：动态任务图。在此基础上，我们提供两种模型：并行任务和actors。
- en: 'To talk about parallel tasks, here is Python code: one reads an array from
    a file, and the other adds two arrays. The code is simple: it creates two arrays
    a and b from file1 and file2, and sum them up. So now, parallelizing this program
    is quite easy. If we want to parallelize a function, in order to do that, we need
    to add a ray.remote decorator to each function. When we invoke these functions,
    you need to invoke remote method. Remove doesn''t return object itself, just the
    object id. This is very similar to the futures abstraction. To get the actual
    object, you must invoke ray.get on the object id.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要讨论并行任务，这里是 Python 代码：一个从文件读取数组，另一个将两个数组相加。代码很简单：它从 file1 和 file2 创建了两个数组 a
    和 b，并将它们相加。所以现在，很容易并行化这个程序。如果我们想要并行化一个函数，为了做到这一点，我们需要为每个函数添加一个 ray.remote 装饰器。当我们调用这些函数时，需要调用
    remote 方法。Remote 不会返回对象本身，只返回对象标识符。这与 futures 抽象非常相似。要获取实际对象，必须对对象标识符调用 ray.get。
- en: To get a better idea of how Ray is executing, let's execute a simple program.
    Assumes files stored on different nodes. When read_array on file1, it schedules
    read_array on the appropriate node. The remote call returns immediately, before
    the actual read finishes. This allows the driver to run the second task in parallel,
    running on the node on file 2, and launch the add remote function. All functions
    have been scheduled remotely, but none of them have finished. To actually get
    the result, you have to call ray.get on the result. This is a blocking call, you'll
    wait for the entire computation graph to be executed.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要更好地了解 Ray 如何执行，让我们执行一个简单的程序。假设文件存储在不同的节点上。当在 file1 上执行 read_array 时，它会安排在适当的节点上执行
    read_array。远程调用会立即返回，而实际读取尚未完成。这允许驱动程序并行运行第二个任务，运行在 file2 上的节点，并启动 add remote
    函数。所有函数都已远程调度，但还没有完成。要实际获取结果，你必须对结果调用 ray.get。这是一个阻塞调用，你将等待整个计算图被执行完毕。
- en: Tasks are very general, but they are not enough. Consider that you want to run
    a simulator, and this simulator is closed source. In this case, you do not have
    access to the state. You have state, action, simulations, to set up state in simulator,
    you cannot do it. So to get around this, there is another use case, where the
    state is too expensive to create. For example, DNNs on GPUs, in this case, you
    want to initialize it once, and reinitialize for each simulation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Tasks 非常通用，但这还不够。考虑你想要运行一个模拟器，而这个模拟器是闭源的。在这种情况下，你无法访问状态。你有状态、动作、模拟，为了在模拟器中设置状态，你无法做到。所以为了解决这个问题，还有另一种用例，即状态创建成本过高的情况。例如，在
    GPU 上的深度神经网络中，你希望初始化一次，并且为每次模拟重新初始化。
- en: In order to address these use cases, we add Actor abstraction. An actor is just
    a remote class. If you have a Counter, you mark it ray.remote, and the when you
    create the class or invoke methods, you use remote keyword. This is a computation
    graph for this very simple example. Notice the method invocations also return
    object identifiers. To get the results, you need to call ray.get on object identifiers.
    Ray also allows you to specify the number of resources, for actors and tasks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些用例，我们添加了 Actor 抽象。一个 actor 只是一个远程类。如果你有一个计数器 Counter，你标记它为 ray.remote，然后在创建类或调用方法时使用
    remote 关键字。这是一个非常简单的示例的计算图。注意方法调用也返回对象标识符。要获取结果，你需要对对象标识符调用 ray.get。Ray 还允许你为
    actors 和 tasks 指定资源数量。
- en: To put things together, and provide a more realistic example, evaluation strategy,
    a scalable form of RL, by Salimans et al in OpenAI. In a nutshell, evolution strategy,
    tries lots of policies, and tries to see which runs best. This is highly parallel.
    So here is pseudocode for parallel strategies. A worker that does simulation and
    returns the reward, create twenty workers, and then 200, do 200 simulations, update
    policy. Again, if you want to parallelize this code, we have to add a bunch of
    remote, and now on the right hand side, you'll notice I'm also sharing the computation
    graph. When you invoke now, the Worker.remote, you create 20 remote workers to
    do it in parallel. And you invoke with the remote keyword. Again, notice that
    in this case, the results are not the rewards themselves, but they're ids to the
    reward objects. In order to get the rewards to get policy, you have to call ray.get.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 综合起来，为了提供一个更现实的例子，评估策略是Salimans等人在OpenAI中提出的一种可扩展的RL形式。简而言之，进化策略尝试许多策略，并尝试看哪一个运行效果最好。这是高度并行的。因此，这里是并行策略的伪代码。一个做模拟并返回奖励的工作者，创建二十个工作者，然后两百个，进行两百次模拟，更新策略。同样地，如果您想并行化此代码，我们必须添加一堆远程，并且现在在右侧，您会注意到我也在共享计算图。当您调用Worker.remote时，您会创建20个远程工作者来并行执行它。您使用远程关键字调用。再次注意，在这种情况下，结果不是奖励本身，而是奖励对象的ID。为了获取奖励以获取策略，您必须调用ray.get。
- en: This hopefully gives you a flavor how to program in Ray. Next time, I switch
    gears, presents system design of Ray; how Ray gets high performance and scalability.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这能给你一点关于如何在Ray中编程的风味。下次，我会转换方向，介绍Ray的系统设计；Ray如何实现高性能和可扩展性。
- en: Like many classic computing frameworks, it has a driver, and a bunch of workers.
    Driver runs a program, worker runs task remotely. You can run and write a bunch
    of actors. The drivers actors on the same node, they share the data, on shared
    memory, and the workers and actors of cross nodes, share through distributed object
    store we built. Each node has a local scheduler, so when a driver wants to run
    another task, the local scheduler tries to schedule it locally. If it cannot schedule
    it locally, it invokes global scheduler, and it will schedule another node that
    has resources. Actor, remote method. Finally, what we do, and one essential part
    of the design, is we have a Global Control State. It takes all of the state of
    the system, and centralizes it. The metadata for the objects, in objects table,
    function. This allows system to be stateless. All these other components can fail,
    you can bring them up, get the most recent data from global control state. It
    also allows us to parallelize the global scheduler, because these replicas are
    going to share the same state in the GCS.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 就像许多经典的计算框架一样，它有一个**驱动程序**和一群**工作者**。驱动程序运行一个程序，工作者远程运行任务。你可以运行和编写一群**演员**。驱动器上的演员在同一节点上，它们共享数据，在共享内存上，工作者和跨节点的演员通过我们构建的分布式对象存储进行共享。每个节点都有一个本地调度程序，因此当驱动程序想要运行另一个任务时，本地调度程序会尝试在本地进行调度。如果无法在本地调度，则调用全局调度程序，并且将在具有资源的另一节点上进行调度。演员，远程方法。最后，我们所做的，设计的一个重要部分，就是我们有一个全局控制状态。它获取系统的所有状态，并对其进行集中管理。对象表的对象的元数据，函数。这使系统成为无状态的。所有这些其他组件都可能失败，您可以将它们启动起来，并从全局控制状态获取最新的数据。它还允许我们对全局调度程序进行并行化处理，因为这些复制品将共享GCS中的相同状态。
- en: Another nice effect of having a GCS is that it makes it easy to build a bunch
    of profiling and debugging tools.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有GCS的另一个好处是，它使构建一群分析和调试工具变得容易。
- en: 'This design is highly scalable. Let me try to convince you why this is. To
    make GcS scalable, we just shard it. All these keys are pseudorandom, so it''s
    easy to shard and load balance. The scheduler as you see is distributed; each
    node has a local scheduler, and Ray tries to schedule tasks which are spawned
    by a worker/driver on another task that is locally. The global scheduler, becomes
    a bottleneck, we can also replicate it. Finally, in systems, even if scheduler
    is super scalable, in Spark, there''s another bottleneck: only the driver can
    launch new tasks. In order to get around that, we allow in Ray the workers and
    actors to launch tasks. Really, there is no single bottleneck point.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此设计具有高度可扩展性。让我试着说服你为什么这样。要使GCS可扩展，我们只需将其分片。所有这些密钥都是伪随机的，因此易于分片和负载平衡。正如您所见，调度程序是分布式的；每个节点都有一个本地调度程序，Ray尝试调度由工作者/驱动程序生成的任务，该任务是本地生成的另一个任务。全局调度程序成为一个瓶颈，我们还可以复制它。最后，在系统中，即使调度程序超级可扩展，在Spark中，还有另一个瓶颈：只有驱动程序可以启动新任务。为了解决这个问题，在Ray中，我们允许工作者和演员启动任务。实际上，没有单一的瓶颈点。
- en: A few words about implementation. The GCS is implemented with Redis. For object
    store, we leverage Apache Arrow. For fault tolerance, we use lineage based fault
    tolerance like Spark. Actors are part of task graph; methods are treated as tasks,
    so we have a uniform model for providing fault tolerance.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 关于实现的一些话。GCS采用Redis实现。对于对象存储，我们利用Apache Arrow。对于容错性，我们使用基于线age的容错性，类似于Spark。Actor是任务图的一部分；方法被视为任务，因此我们有一个统一的模型来提供容错性。
- en: So now some evaluation results. This plot represents the number of tasks per
    second, and you can see the number of nodes; it scales linearly. You can schedule
    over 1.8 M/s. Latency of local task execution is 300us, the latency of remote
    task is 1ms. This plot illustrates fault tolerance. You may ask why you care about
    fault tolerance? The problem is you need in your program that the simulation may
    not finish; this makes the program far more complicated, even if you're willing
    to ignore some results. Here, on this axis, you have the time in seconds, you
    have two y axes, number of nodes in system, and the throughput. As you can see,
    the number of nodes is starting at 50, then 25, then to 10, and goes back to 50\.
    In the red area, you show the number of tasks per second; it follows as you may
    expect, the number of nodes in the system. If you look a little bit, there are
    some drops; every time, you have a drop in the number of tasks. It turns out this
    is because of the object reconstruction. When some nodes go away, you lose the
    objects on the node, so you have to reconstruct them. Ray and Spark reconstruct
    them transparently. With blue, you can see the re-executed tasks. If you add them,
    you get a very nice filling curve.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是一些评估结果。这张图表示每秒的任务数，您可以看到节点数；它线性扩展。您可以安排超过1.8M/s。本地任务执行的延迟为300微秒，远程任务的延迟为1毫秒。这张图说明了容错性。您可能会问为什么关心容错性？问题在于，程序中可能需要模拟未完成；即使您愿意忽略一些结果，这也使程序变得更加复杂。在这个轴上，您有秒数的时间，有两个Y轴，系统中的节点数和吞吐量。正如您所见，节点数从50开始，然后是25，然后到10，再回到50。在红色区域，显示每秒的任务数；正如您所预期的那样，与系统中的节点数一致。如果您仔细看一下，会有一些下降；每次您都会看到任务数下降。事实证明，这是由于对象重建引起的。当某些节点离开时，您会丢失节点上的对象，因此必须对其进行重建。Ray和Spark会自动透明地重建它们。通过蓝色，您可以看到重新执行的任务。如果将它们加起来，您将得到一个非常漂亮的填充曲线。
- en: Finally, for evolution strategies, we compared with reference ES from... we
    followed the OpenAI, and on the X axis, you have number of CPUs, mean time to
    solve the particular problem; simulator, learning to run, there are three points
    to notice. One is, as expected, as you add more CPUs, the time to solve goes down.
    The second is that Ray is actually better than the reference ES, better results,
    even though the reference ES is specialized for beating. Third, for a very large
    number of CPUs, ref couldn't do it, but Ray could do better and better. I should
    add that Ray takes half the amount of code, and was implemented in a couple of
    hours.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于进化策略，我们与参考的ES进行了比较……我们遵循了OpenAI的方式，在X轴上，您有CPU的数量，解决特定问题的平均时间；模拟器，学习运行，有三点值得注意。一是如预期的那样，随着CPU数量的增加，解决问题的时间减少。第二是Ray实际上比参考ES更好，获得了更好的结果，即使参考ES专门用于击败。第三，对于非常大量的CPU，参考ES无法做到，但Ray可以做得越来越好。我应该补充说Ray只需要一半的代码量，并且在几个小时内实现了。
- en: 'Related work: look, in this area, there are a huge number of systems, that''s
    why you are here, lots of systems. Ray is complimentary to TF, MXNet, PyTorch,
    etc. We use these systems to implement DNNs. We integrate with TF and PyT. There
    are more general systems, like MPI and Spark; these have limited support for nested
    parallelism; computation model, and they have much coarser grained tasks.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 相关工作：在这个领域，有大量的系统，这就是你在这里的原因，很多系统。Ray与TF、MXNet、PyTorch等相辅相成。我们使用这些系统来实现DNNs。我们与TF和PyT进行集成。还有一些更通用的系统，如MPI和Spark；它们对嵌套并行性、计算模型有一定的支持，任务粒度更粗。
- en: 'To conclude, Ray is a system for high performance and flexibility and scalability.
    We have two libraries on top of Ray: RLlib and Ray Tune. It''s open source, please
    try, we''d love your feedback. Robert, Philip, Alex, Stephanie, Richard, Eric,
    Heng, William, and many thanks to my colleague Michael Jordan.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，Ray是一个高性能、灵活和可扩展的系统。我们在Ray的基础上有两个库：RLlib和Ray Tune。它是开源的，请试用，我们很乐意听取您的反馈。感谢我的同事迈克尔·乔丹以及罗伯特、菲利普、亚历克斯、斯蒂芬妮、理查德、埃里克、恒、威廉等人。
- en: 'Q: In your system, you also use actor; actor is built up on shared memory.
    Do you have separate mailbox for actors? How do you do that?'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: 在你们的系统中，你们也使用了 actor；actor 是建立在共享内存上的。你们有单独的邮箱给 actor 吗？你们是怎么做到的？'
- en: 'A: No, the actors communicate by passing the argument to the shared object
    store.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 不，actor 通过将参数传递给共享对象存储进行通信。'
- en: 'Q: What is the granularity of parallelism? Is it task atomic, or do you split
    task?'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: 并行性的粒度是什么？它是任务原子的，还是将任务分割了？'
- en: 'A: The task granularity is given by what is the overhead for launching a task
    and scheduling the task. The task you see, we are targeting task, low and few
    ms. The task is not implementing something like activation function. we leave
    that job to much better frameworks. And a task is executing atomically, a method,
    in the actors, are serialized.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 任务的粒度由启动任务和调度任务的开销决定。你看到的任务，我们的目标是任务、低延迟和少量的 ms。任务不是实现类似激活函数的东西。我们把这项工作留给更好的框架。任务是以原子方式执行的，方法在
    actor 中是串行化的。'
- en: 'Q: Question about fault tolerance: in Spark, when you don''t have a response
    for some time, it says this node died. Here, the task is much more, because NN,
    something like that. So we don''t have the same time.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: 在 Spark 中关于容错性的问题：当一段时间没有响应时，它会说这个节点死了。这里，任务更多，因为 NN，类似这样的东西。所以我们没有相同的时间。'
- en: 'A: We do not do speculation; implicit speculation in Ray, for the reason you
    mentioned.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 我们不进行猜测；Ray 中的隐式猜测，出于你提到的原因。'
- en: 'Q: Can you give me more details on the reference implementation, doesn''t scale'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: 你能详细说明一下参考实现，它不具备可伸缩性'
- en: 'A: The reference implementation, it''s the OpenAI implementation, Robert here
    can provide you a lot more detailed answers to that question.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 参考实现，这是 OpenAI 的实现，Robert 在这里可以为您提供更详细的答案。'
