- en: An Overview of Deep Learning for Curious People
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对好奇的人的深度学习概述
- en: 原文：[https://lilianweng.github.io/posts/2017-06-21-overview/](https://lilianweng.github.io/posts/2017-06-21-overview/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://lilianweng.github.io/posts/2017-06-21-overview/](https://lilianweng.github.io/posts/2017-06-21-overview/)
- en: (The post was originated from my talk for [WiMLDS x Fintech meetup](http://wimlds.org/chapters/about-bay-area/)
    hosted by [Affirm](www.affirm.com).)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: （本文源自我在[WiMLDS x Fintech meetup](http://wimlds.org/chapters/about-bay-area/)上的演讲，由[Affirm](www.affirm.com)主办。）
- en: I believe many of you have watched or heard of the [games](https://youtu.be/vFr3K2DORc8)
    between AlphaGo and professional Go player [Lee Sedol](https://en.wikipedia.org/wiki/Lee_Sedol)
    in 2016\. Lee has the highest rank of nine dan and many world championships. No
    doubt, he is one of the best Go players in the world, but he [lost by 1-4](https://www.scientificamerican.com/article/how-the-computer-beat-the-go-master/)
    in this series versus AlphaGo. Before this, Go was considered to be an intractable
    game for computers to master, as its simple rules lay out an exponential number
    of variations in the board positions, many more than what in Chess. This event
    surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention
    has been attracted to the progress of AI.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信很多人都看过或听说过2016年AlphaGo和职业围棋选手[李世石](https://en.wikipedia.org/wiki/Lee_Sedol)之间的[比赛](https://youtu.be/vFr3K2DORc8)。李世石是九段最高段位和多次世界冠军。毫无疑问，他是世界上最优秀的围棋选手之一，但在这次与AlphaGo的系列比赛中，他以1-4的比分[输掉了比赛](https://www.scientificamerican.com/article/how-the-computer-beat-the-go-master/)。在此之前，围棋被认为是计算机难以掌握的游戏，因为其简单的规则在棋盘位置上提供了指数级别的变化，远远超过国际象棋。这一事件无疑将2016年归为人工智能的重要一年。由于AlphaGo，人们对人工智能的进展引起了很多关注。
- en: Meanwhile, many companies are spending resources on pushing the edges of AI
    applications, that indeed have the potential to change or even revolutionize how
    we are gonna live. Familiar examples include self-driving cars, chatbots, home
    assistant devices and many others. One of the secret receipts behind the progress
    we have had in recent years is deep learning.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，许多公司正在投入资源推动人工智能应用的边界，这确实有潜力改变甚至彻底改变我们的生活方式。熟悉的例子包括自动驾驶汽车、聊天机器人、家庭助手设备等。近年来我们取得进展的秘密之一就是深度学习。
- en: Why Does Deep Learning Work Now?
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么深度学习现在有效？
- en: 'Deep learning models, in simple words, are large and deep artificial neural
    nets. A neural network (“NN”) can be well presented in a [directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph):
    the input layer takes in signal vectors; one or multiple hidden layers process
    the outputs of the previous layer. The initial concept of a neural network can
    be traced back to more than [half a century ago](https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html).
    But why does it work now? Why do people start talking about them all of a sudden?'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，深度学习模型是大型且深层的人工神经网络。神经网络（“NN”）可以用[有向无环图](https://en.wikipedia.org/wiki/Directed_acyclic_graph)很好地表示：输入层接收信号向量；一个或多个隐藏层处理前一层的输出。神经网络的最初概念可以追溯到[半个多世纪前](https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html)。但为什么现在它有效？为什么人们突然开始谈论它们？
- en: '![](../Images/6395341b1b48fca87b40a0024e698d45.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6395341b1b48fca87b40a0024e698d45.png)'
- en: 'Fig. 1\. A three-layer artificial neural network. (Image source: [http://cs231n.github.io/convolutional-networks/#conv](http://cs231n.github.io/convolutional-networks/#conv))'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 一个三层人工神经网络。（图片来源：[http://cs231n.github.io/convolutional-networks/#conv](http://cs231n.github.io/convolutional-networks/#conv)）
- en: 'The reason is surprisingly simple:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 原因出奇的简单：
- en: We have a lot **more data**.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有**更多的数据**。
- en: We have **much powerful computers**.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有**更强大的计算机**。
- en: A large and deep neural network has many more layers + many more nodes in each
    layer, which results in exponentially many more parameters to tune. Without enough
    data, we cannot learn parameters efficiently. Without powerful computers, learning
    would be too slow and insufficient.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个大而深的神经网络有更多的层次和更多的节点，每一层都有更多的节点，这导致需要调整的参数数量呈指数增长。没有足够的数据，我们无法有效地学习参数。没有强大的计算机，学习将会太慢且不足够。
- en: Here is an interesting plot presenting the relationship between the data scale
    and the model performance, proposed by Andrew Ng in his “[Nuts and Bolts of Applying
    Deep Learning](https://youtu.be/F1ka6a13S9I)” talk. On a small dataset, traditional
    algorithms (Regression, Random Forests, SVM, GBM, etc.) or statistical learning
    does a great job, but once the data scale goes up to the sky, the large NN outperforms
    others. Partially because compared to a traditional ML model, a neural network
    model has many more parameters and has the capability to learn complicated nonlinear
    patterns. Thus we expect the model to pick the most helpful features by itself
    without too much expert-involved manual feature engineering.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个有趣的图表，展示了数据规模与模型性能之间的关系，由Andrew Ng在他的“[应用深度学习的要点](https://youtu.be/F1ka6a13S9I)”演讲中提出。在小数据集上，传统算法（回归、随机森林、支持向量机、梯度提升机等）或统计学习表现出色，但一旦数据规模飙升，大型神经网络胜过其他模型。部分原因是与传统机器学习模型相比，神经网络模型有更多参数，并且具有学习复杂非线性模式的能力。因此，我们期望模型能够自行选择最有用的特征，而无需太多专家参与的手动特征工程。
- en: '![](../Images/deb8f2d4b8ceab0b159fe0c0196f4316.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/deb8f2d4b8ceab0b159fe0c0196f4316.png)'
- en: 'Fig. 2\. The data scale versus the model performance. (Recreated based on:
    [https://youtu.be/F1ka6a13S9I](https://youtu.be/F1ka6a13S9I))'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图2。数据规模与模型性能的关系。（基于重新创建：[https://youtu.be/F1ka6a13S9I](https://youtu.be/F1ka6a13S9I)）
- en: Deep Learning Models
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习模型
- en: Next, let’s go through a few classical deep learning models.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看一些经典的深度学习模型。
- en: Convolutional Neural Network
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: 'Convolutional neural networks, short for “CNN”, is a type of feed-forward artificial
    neural networks, in which the connectivity pattern between its neurons is inspired
    by the organization of the visual cortex system. The primary visual cortex (V1)
    does edge detection out of the raw visual input from the retina. The secondary
    visual cortex (V2), also called prestriate cortex, receives the edge features
    from V1 and extracts simple visual properties such as orientation, spatial frequency,
    and color. The visual area V4 handles more complicated object attributes. All
    the processed visual features flow into the final logic unit, inferior temporal
    gyrus (IT), for object recognition. The shortcut between V1 and V4 inspires a
    special type of CNN with connections between non-adjacent layers: Residual Net
    ([He, et al. 2016](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf))
    containing “Residual Block” which supports some input of one layer to be passed
    to the component two layers later.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络，简称“CNN”，是一种前馈人工神经网络，其神经元之间的连接模式受到视觉皮层系统的组织启发。主要视觉皮层（V1）从视网膜接收原始视觉输入并进行边缘检测。次级视觉皮层（V2），也称为前条皮质，从V1接收边缘特征并提取简单的视觉属性，如方向、空间频率和颜色。视觉区V4处理更复杂的对象属性。所有处理过的视觉特征流向最终的逻辑单元，颞下沟皮质（IT），用于对象识别。V1和V4之间的快捷路径启发了一种特殊类型的CNN，其中包含非相邻层之间的连接：残差网络（[He等，2016](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)），其中的“残差块”支持将一层的某些输入传递到两层后的组件。
- en: '![](../Images/42fc43168dbb19b56d2e2e397843442b.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42fc43168dbb19b56d2e2e397843442b.png)'
- en: 'Fig. 3\. Illustration of the human visual cortex system. (Image source: [Wang
    & Raj 2017](https://arxiv.org/abs/1702.07800))'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图3。人类视觉皮层系统的插图。（图片来源：[Wang & Raj 2017](https://arxiv.org/abs/1702.07800)）
- en: Convolution is a mathematical term, here referring to an operation between two
    matrices. The convolutional layer has a fixed small matrix defined, also called
    kernel or filter. As the kernel is sliding, or convolving, across the matrix representation
    of the input image, it is computing the element-wise multiplication of the values
    in the kernel matrix and the original image values. [Specially designed kernels](http://setosa.io/ev/image-kernels/)
    can process images for common purposes like blurring, sharpening, edge detection
    and many others, fast and efficiently.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是一个数学术语，这里指的是两个矩阵之间的操作。卷积层有一个固定的小矩阵定义，也称为核或滤波器。当核滑动或卷积穿过输入图像的矩阵表示时，它计算核矩阵中的值和原始图像值的逐元素乘积。[特别设计的核](http://setosa.io/ev/image-kernels/)可以快速高效地处理图像，用于常见目的如模糊、锐化、边缘检测等。
- en: '![](../Images/5362f324530b74b21d5b6e6d92a108eb.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5362f324530b74b21d5b6e6d92a108eb.png)'
- en: 'Fig. 4\. The LeNet architecture consists of two sets of convolutional, activation,
    and pooling layers, followed by a fully-connected layer, activation, another fully-connected
    layer, and finally a softmax classifier (Image source: [http://deeplearning.net/tutorial/lenet.html](http://deeplearning.net/tutorial/lenet.html))'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图4\. LeNet架构由两组卷积、激活和池化层组成，接着是一个全连接层、激活、另一个全连接层，最后是一个softmax分类器（图片来源：[http://deeplearning.net/tutorial/lenet.html](http://deeplearning.net/tutorial/lenet.html)）
- en: '[Convolutional](http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/)
    and [pooling](http://ufldl.stanford.edu/tutorial/supervised/Pooling/) (or “sub-sampling”
    in Fig. 4) layers act like the V1, V2 and V4 visual cortex units, responding to
    feature extraction. The object recognition reasoning happens in the later fully-connected
    layers which consume the extracted features.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[卷积](http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/)和[池化](http://ufldl.stanford.edu/tutorial/supervised/Pooling/)（或图4中的“子采样”）层类似于V1、V2和V4视觉皮层单元，响应特征提取。对象识别推理发生在后续的全连接层中，这些层使用提取的特征。'
- en: Recurrent Neural Network
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 递归神经网络
- en: A sequence model is usually designed to transform an input sequence into an
    output sequence that lives in a different domain. Recurrent neural network, short
    for “RNN”, is suitable for this purpose and has shown tremendous improvement in
    problems like handwriting recognition, speech recognition, and machine translation
    ([Sutskever et al. 2011](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf),
    [Liwicki et al. 2007](http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 序列模型通常被设计用于将一个输入序列转换为生活在不同领域的输出序列。短语“RNN”代表递归神经网络，适用于此目的，并在手写识别、语音识别和机器翻译等问题上显示出巨大改进（[Sutskever
    et al. 2011](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf)，[Liwicki
    et al. 2007](http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf)）。
- en: A recurrent neural network model is born with the capability to process long
    sequential data and to tackle tasks with context spreading in time. The model
    processes one element in the sequence at one time step. After computation, the
    newly updated unit state is passed down to the next time step to facilitate the
    computation of the next element. Imagine the case when an RNN model reads all
    the Wikipedia articles, character by character, and then it can predict the following
    words given the context.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 递归神经网络模型具有处理长序列数据和处理具有时间上下文传播的任务的能力。该模型在一个时间步中处理序列中的一个元素。计算后，新更新的单元状态传递到下一个时间步以促进下一个元素的计算。想象一下，当一个RNN模型逐个字符地阅读所有维基百科文章时，然后它可以根据上下文预测接下来的单词。
- en: '![](../Images/afe7794966b70dc9894dbd0c766fd68f.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afe7794966b70dc9894dbd0c766fd68f.png)'
- en: 'Fig. 5\. A recurrent neural network with one hidden unit (left) and its unrolling
    version in time (right). The unrolling version illustrates what happens in time:
    $s\_{t-1}$, $s\_{t}$, and $s\_{t+1}$ are the same unit with different states at
    different time steps $t-1$, $t$, and $t+1$. (Image source: [LeCun, Bengio, and
    Hinton, 2015](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf);
    [Fig. 5](https://www.nature.com/nature/journal/v521/n7553/fig_tab/nature14539_F5.html))'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图5\. 一个具有一个隐藏单元的递归神经网络（左）及其在时间上展开的版本（右）。展开版本说明了时间上发生的事情：$s\_{t-1}$、$s\_{t}$和$s\_{t+1}$是相同的单元，在不同时间步$t-1$、$t$和$t+1$具有不同状态。（图片来源：[LeCun,
    Bengio, and Hinton, 2015](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf);
    [图5](https://www.nature.com/nature/journal/v521/n7553/fig_tab/nature14539_F5.html))
- en: However, simple perceptron neurons that linearly combine the current input element
    and the last unit state may easily lose the long-term dependencies. For example,
    we start a sentence with “Alice is working at …” and later after a whole paragraph,
    we want to start the next sentence with “She” or “He” correctly. If the model
    forgets the character’s name “Alice”, we can never know. To resolve the issue,
    researchers created a special neuron with a much more complicated internal structure
    for memorizing long-term context, named [“Long-short term memory (LSTM)”](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)
    cell. It is smart enough to learn for how long it should memorize the old information,
    when to forget, when to make use of the new data, and how to combine the old memory
    with new input. This [introduction](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    is so well written that I recommend everyone with interest in LSTM to read it.
    It has been officially promoted in the [Tensorflow documentation](https://www.tensorflow.org/tutorials/recurrent)
    ;-)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，简单的感知器神经元线性组合当前输入元素和上一个单元状态可能会轻易丢失长期依赖关系。例如，我们以“爱丽丝正在工作…”开头一句，然后在整个段落后，我们想要用“她”或“他”正确开始下一句。如果模型忘记了人物的名字“爱丽丝”，我们就永远不会知道。为了解决这个问题，研究人员创建了一个具有更复杂内部结构的特殊神经元，用于记忆长期上下文，名为[“长短期记忆（LSTM）”](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)单元。它足够聪明，可以学习应该记住旧信息多长时间，何时遗忘，何时利用新数据，以及如何将旧记忆与新输入结合起来。这篇[介绍](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)写得非常好，我建议所有对LSTM感兴趣的人阅读。它已经在[Tensorflow文档](https://www.tensorflow.org/tutorials/recurrent)中正式推广
    ;-)
- en: '![](../Images/2269803731918b77c850bf1ba23a5120.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2269803731918b77c850bf1ba23a5120.png)'
- en: 'Fig. 6\. The structure of a LSTM cell. (Image source: [http://colah.github.io/posts/2015-08-Understanding-LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs))'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '图6. LSTM单元的结构。 (图片来源: [http://colah.github.io/posts/2015-08-Understanding-LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs))'
- en: To demonstrate the power of RNNs, [Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
    built a character-based language model using RNN with LSTM cells. Without knowing
    any English vocabulary beforehand, the model could learn the relationship between
    characters to form words and then the relationship between words to form sentences.
    It could achieve a decent performance even without a huge set of training data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示循环神经网络（RNN）的强大之处，[Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
    使用带有LSTM单元的RNN构建了一个基于字符的语言模型。在事先不知道任何英语词汇的情况下，该模型可以学习字符之间的关系以形成单词，然后学习单词之间的关系以形成句子。即使没有大量的训练数据，它也能取得不错的性能。
- en: '![](../Images/387ae59519145a9aaf72ef5c9fda65f1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/387ae59519145a9aaf72ef5c9fda65f1.png)'
- en: 'Fig. 7\. A character-based recurrent neural network model writes like a Shakespeare.
    (Image source: [http://karpathy.github.io/2015/05/21/rnn-effectiveness](http://karpathy.github.io/2015/05/21/rnn-effectiveness))'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '图7. 基于字符的循环神经网络模型写作像莎士比亚。 (图片来源: [http://karpathy.github.io/2015/05/21/rnn-effectiveness](http://karpathy.github.io/2015/05/21/rnn-effectiveness))'
- en: 'RNN: Sequence-to-Sequence Model'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'RNN: 序列到序列模型'
- en: The [sequence-to-sequence model](https://arxiv.org/pdf/1406.1078.pdf) is an
    extended version of RNN, but its application field is distinguishable enough that
    I would like to list it in a separated section. Same as RNN, a sequence-to-sequence
    model operates on sequential data, but particularly it is commonly used to develop
    chatbots or personal assistants, both generating meaningful response for input
    questions. A sequence-to-sequence model consists of two RNNs, encoder and decoder.
    The encoder learns the contextual information from the input words and then hands
    over the knowledge to the decoder side through a “**context vector**” (or “thought
    vector”, as shown in Fig 8.). Finally, the decoder consumes the context vector
    and generates proper responses.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[序列到序列模型](https://arxiv.org/pdf/1406.1078.pdf) 是RNN的扩展版本，但其应用领域有足够的区别，我想单独列出来。与RNN一样，序列到序列模型操作顺序数据，但特别常用于开发聊天机器人或个人助手，为输入问题生成有意义的回应。序列到序列模型由两个RNN组成，编码器和解码器。编码器从输入单词中学习上下文信息，然后通过“**上下文向量**”（或“思考向量”，如图8所示）将知识传递给解码器。最后，解码器使用上下文向量生成适当的回应。'
- en: '![](../Images/ee729f893fec4aae3971521fd9c1e2dc.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee729f893fec4aae3971521fd9c1e2dc.png)'
- en: 'Fig. 8\. A sequence-to-sequence model for generating Gmail auto replies. (Image
    source: [https://research.googleblog.com/2015/11/computer-respond-to-this-email.html](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html))'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8\. 用于生成 Gmail 自动回复的序列到序列模型。（图片来源：[https://research.googleblog.com/2015/11/computer-respond-to-this-email.html](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)）
- en: Autoencoders
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动编码器
- en: Different from the previous models, autoencoders are for unsupervised learning.
    It is designed to learn a **low-dimensional** representation of a **high-dimensional**
    data set, similar to what [Principal Components Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis)
    does. The autoencoder model tries to learn an approximation function $ f(x) \approx
    x $ to reproduce the input data. However, it is restricted by a bottleneck layer
    in the middle with a very small number of nodes. With limited capacity, the model
    is forced to form a very efficient encoding of the data, that is essentially the
    low-dimensional code we learned.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与先前的模型不同，自动编码器用于无监督学习。它旨在学习**低维**表示**高维**数据集，类似于[主成分分析（PCA）](https://en.wikipedia.org/wiki/Principal_component_analysis)的做法。自动编码器模型尝试学习一个近似函数
    $ f(x) \approx x $ 来复制输入数据。然而，它受到中间具有非常少节点的瓶颈层的限制。由于容量有限，模型被迫形成数据的非常高效编码，这本质上就是我们学到的低维代码。
- en: '![](../Images/61cdc6cabf29ed29c44756da2fded700.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61cdc6cabf29ed29c44756da2fded700.png)'
- en: 'Fig. 9\. An autoencoder model has a bottleneck layer with only a few neurons.
    (Image source: Geoffrey Hinton’s Coursera class ["Neural Networks for Machine
    Learning"](https://www.coursera.org/learn/neural-networks) - [Week 15](https://www.coursera.org/learn/neural-networks/home/week/15))'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. 自动编码器模型具有仅有少量神经元的瓶颈层。（图片来源：Geoffrey Hinton 的 Coursera 课程["神经网络与机器学习"](https://www.coursera.org/learn/neural-networks)
    - [第 15 周](https://www.coursera.org/learn/neural-networks/home/week/15)）
- en: '[Hinton and Salakhutdinov](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)
    used autoencoders to compress documents on a variety of topics. As shown in Fig
    10, when both PCA and autoencoder were applied to reduce the documents onto two
    dimensions, autoencoder demonstrated a much better outcome. With the help of autoencoder,
    we can do efficient data compression to speed up the information retrieval including
    both documents and images.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hinton 和 Salakhutdinov](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)
    使用自动编码器对各种主题的文档进行压缩。如图 10 所示，当同时应用 PCA 和自动编码器将文档压缩到二维时，自动编码器表现出更好的结果。借助自动编码器，我们可以进行高效的数据压缩，加快信息检索的速度，包括文档和图像。'
- en: '![](../Images/4fd189f148662ce4f6599c9909331d05.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fd189f148662ce4f6599c9909331d05.png)'
- en: 'Fig. 10\. The outputs of PCA (left) and autoencoder (right) when both try to
    compress documents into two numbers. (Image source: [Hinton & Salakhutdinov 2006](https://www.cs.toronto.edu/~hinton/science.pdf))'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10\. 当 PCA 和自动编码器尝试将文档压缩为两个数字时的输出。（图片来源：[Hinton & Salakhutdinov 2006](https://www.cs.toronto.edu/~hinton/science.pdf)）
- en: Reinforcement (Deep) Learning
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化（深度）学习
- en: Since I started my post with AlphaGo, let us dig a bit more on why AlphaGo worked
    out. [Reinforcement learning (“RL”)](https://en.wikipedia.org/wiki/Reinforcement_learning)
    is one of the secrets behind its success. RL is a subfield of machine learning
    which allows machines and software agents to automatically determine the optimal
    behavior within a given context, with a goal to maximize the long-term performance
    measured by a given metric.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我在帖子中以 AlphaGo 开头，让我们更深入地了解为什么 AlphaGo 取得成功。[强化学习（"RL"）](https://en.wikipedia.org/wiki/Reinforcement_learning)
    是其成功背后的秘密之一。RL 是机器学习的一个子领域，允许机器和软件代理在给定上下文中自动确定最佳行为，目标是通过给定的度量标准最大化长期性能。
- en: '![](../Images/44e6d4729f71b8419f8672d2ed524c65.png) ![](../Images/25c814659e7592d12edb2584417f68f1.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44e6d4729f71b8419f8672d2ed524c65.png) ![](../Images/25c814659e7592d12edb2584417f68f1.png)'
- en: 'Fig. 11\. AlphaGo neural network training pipeline and architecture. (Image
    source: [Silver et al. 2016](https://www.nature.com/articles/nature16961))'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11\. AlphaGo 神经网络训练流程和架构。（图片来源：[Silver 等人 2016](https://www.nature.com/articles/nature16961)）
- en: The AlphaGo system starts with a supervised learning process to train a fast
    rollout policy and a policy network, relying on the manually curated training
    dataset of professional players’ games. It learns what is the best strategy given
    the current position on the game board. Then it applies reinforcement learning
    by setting up self-play games. The RL policy network gets improved when it wins
    more and more games against previous versions of the policy network. In the self-play
    stage, AlphaGo becomes stronger and stronger by playing against itself without
    requiring additional external training data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: AlphaGo系统从一个监督学习过程开始，训练一个快速展开策略和一个策略网络，依赖于专业玩家游戏的手动策划训练数据集。它学习在游戏棋盘上的当前位置给出最佳策略。然后，通过设置自我对弈游戏来应用强化学习。当RL策略网络在与以前版本的策略网络对战中赢得越来越多的游戏时，它得到改进。在自我对弈阶段，AlphaGo通过与自己对战而不需要额外的外部训练数据变得越来越强大。
- en: Generative Adversarial Network
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: '[Generative adversarial network](https://arxiv.org/pdf/1406.2661.pdf), short
    for “GAN”, is a type of deep generative models. GAN is able to create new examples
    after learning through the real data. It is consist of two models competing against
    each other in a zero-sum game framework. The famous deep learning researcher [Yann
    LeCun](http://yann.lecun.com/) gave it a super high praise: Generative Adversarial
    Network is the most interesting idea in the last ten years in machine learning.
    (See the Quora question: [“What are some recent and potentially upcoming breakthroughs
    in deep learning?”](https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning))'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[生成对抗网络](https://arxiv.org/pdf/1406.2661.pdf)，简称“GAN”，是一种深度生成模型。GAN能够通过真实数据学习后创建新的示例。它由两个在零和博弈框架中相互竞争的模型组成。著名的深度学习研究员[Yann
    LeCun](http://yann.lecun.com/)对其给予了极高的评价：生成对抗网络是过去十年中机器学习中最有趣的想法。（参见Quora问题：[“深度学习中一些最近和可能即将发生的突破是什么？”](https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning)）'
- en: '![](../Images/75788e705ec2c612c9034c3f8bf8af0d.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75788e705ec2c612c9034c3f8bf8af0d.png)'
- en: 'Fig. 12\. The architecture of a generative adversarial network. (Image source:
    [http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html](http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html))'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12\. 生成对抗网络的架构。（图片来源：[http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html](http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)）
- en: 'In the [original GAN paper](https://arxiv.org/pdf/1406.2661.pdf), GAN was proposed
    to generate meaningful images after learning from real photos. It comprises two
    independent models: the **Generator** and the **Discriminator**. The generator
    produces fake images and sends the output to the discriminator model. The discriminator
    works like a judge, as it is optimized for identifying the real photos from the
    fake ones. The generator model is trying hard to cheat the discriminator while
    the judge is trying hard not to be cheated. This interesting zero-sum game between
    these two models motivates both to develop their designed skills and improve their
    functionalities. Eventually, we take the generator model for producing new images.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在[原始GAN论文](https://arxiv.org/pdf/1406.2661.pdf)中，GAN被提出用于从真实照片中学习生成有意义的图像。它包括两个独立的模型：**生成器**和**判别器**。生成器产生假图像并将输出发送给判别器模型。判别器像一名法官一样工作，因为它被优化用于识别真实照片和假照片。生成器模型努力欺骗判别器，而判别器努力不被欺骗。这两个模型之间的有趣的零和博弈激励它们发展设计的技能并改进功能。最终，我们采用生成器模型生成新图像。
- en: Toolkits and Libraries
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具包和库
- en: After learning all these models, you may start wondering how you can implement
    the models and use them for real. Fortunately, we have many open source toolkits
    and libraries for building deep learning models. [Tensorflow](https://www.tensorflow.org/)
    is fairly new but has attracted a lot of popularity. It turns out, TensorFlow
    was [the most forked Github project of 2015](http://deliprao.com/archives/168).
    All that happened in a period of 2 months after its release in Nov 2015.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习所有这些模型之后，您可能会想知道如何实现这些模型并将它们用于实际应用。幸运的是，我们有许多用于构建深度学习模型的开源工具包和库。[Tensorflow](https://www.tensorflow.org/)相当新，但已经吸引了很多关注。事实证明，TensorFlow是[2015年最受关注的Github项目](http://deliprao.com/archives/168)。所有这些都发生在2015年11月发布后的2个月内。
- en: '![](../Images/1709f70e5aa87c0abed2dc44b0993d07.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1709f70e5aa87c0abed2dc44b0993d07.png)'
- en: How to Learn?
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何学习？
- en: If you are very new to the field and willing to devote some time to studying
    deep learning in a more systematic way, I would recommend you to start with the
    book [Deep Learning](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?s=books&ie=UTF8&qid=1499413305&sr=1-1&keywords=deep+learning)
    by Ian Goodfellow, Yoshua Bengio, and Aaron Courville. The Coursera course [“Neural
    Networks for Machine Learning”](https://www.coursera.org/learn/neural-networks)
    by Geoffrey Hinton ([Godfather of deep learning!](https://youtu.be/uAu3jQWaN6E)).
    The content for the course was prepared around 2006, pretty old, but it helps
    you build up a solid foundation for understanding deep learning models and expedite
    further exploration.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这个领域非常新，并愿意花一些时间以更系统化的方式学习深度学习，我建议你从Ian Goodfellow、Yoshua Bengio和Aaron Courville合著的书籍[Deep
    Learning](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?s=books&ie=UTF8&qid=1499413305&sr=1-1&keywords=deep+learning)开始。Geoffrey
    Hinton（深度学习教父！）的Coursera课程[“神经网络用于机器学习”](https://www.coursera.org/learn/neural-networks)。该课程的内容是围绕2006年准备的，相当古老，但它可以帮助你建立扎实的深度学习模型理解基础，并加速进一步探索。
- en: Meanwhile, maintain your curiosity and passion. The field is making progress
    every day. Even classical or widely adopted deep learning models may just have
    been proposed 1-2 years ago. Reading academic papers can help you learn stuff
    in depth and keep up with the cutting-edge findings.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，保持好奇心和激情。这个领域每天都在取得进展。即使是经典的或广泛采用的深度学习模型可能也只是在1-2年前提出的。阅读学术论文可以帮助你深入学习知识，并跟上最前沿的发现。
- en: Useful resources
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有用资源
- en: 'Google Scholar: [http://scholar.google.com](http://scholar.google.com)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谷歌学术：[http://scholar.google.com](http://scholar.google.com)
- en: 'arXiv cs section: [https://arxiv.org/list/cs/recent](https://arxiv.org/list/cs/recent)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: arXiv 计算机科学部分：[https://arxiv.org/list/cs/recent](https://arxiv.org/list/cs/recent)
- en: '[Unsupervised Feature Learning and Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无监督特征学习和深度学习教程](http://ufldl.stanford.edu/tutorial/)'
- en: '[Tensorflow Tutorials](https://www.tensorflow.org/tutorials/)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Tensorflow 教程](https://www.tensorflow.org/tutorials/)'
- en: Data Science Weekly
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学周刊
- en: '[KDnuggets](http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets](http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)'
- en: Tons of blog posts and online tutorials
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大量博客文章和在线教程
- en: Related [Cousera](http://coursera.com) courses
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关的[Cousera](http://coursera.com)课程
- en: '[awesome-deep-learning-papers](https://github.com/terryum/awesome-deep-learning-papers)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[awesome-deep-learning-papers](https://github.com/terryum/awesome-deep-learning-papers)'
- en: Blog posts mentioned
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提到的博客文章
- en: '[Explained Visually: Image Kernels](http://setosa.io/ev/image-kernels)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Explained Visually: Image Kernels](http://setosa.io/ev/image-kernels)'
- en: '[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解LSTM网络](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)'
- en: '[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[循环神经网络的不合理有效性](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)'
- en: '[Computer, respond to this email.](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[电脑，回复这封邮件。](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)'
- en: Interesting blogs worthy of checking
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 值得一读的有趣博客
- en: '[www.wildml.com](http://www.wildml.com)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[www.wildml.com](http://www.wildml.com)'
- en: '[colah.github.io](http://colah.github.io/)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[colah.github.io](http://colah.github.io/)'
- en: '[karpathy.github.io](http://karpathy.github.io/)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[karpathy.github.io](http://karpathy.github.io/)'
- en: '[blog.openai.com](https://blog.openai.com)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[blog.openai.com](https://blog.openai.com)'
- en: Papers mentioned
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提到的论文
- en: '[1] He, Kaiming, et al. [“Deep residual learning for image recognition.”](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
    Proc. IEEE Conf. on computer vision and pattern recognition. 2016.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] He, Kaiming, et al. [“用于图像识别的深度残差学习。”](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
    2016年IEEE计算机视觉与模式识别大会论文集。'
- en: '[2] Wang, Haohan, Bhiksha Raj, and Eric P. Xing. [“On the Origin of Deep Learning.”](https://arxiv.org/pdf/1702.07800.pdf)
    arXiv preprint arXiv:1702.07800, 2017.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Wang, Haohan, Bhiksha Raj, and Eric P. Xing. [“深度学习的起源。”](https://arxiv.org/pdf/1702.07800.pdf)
    arXiv预印本 arXiv:1702.07800，2017年。'
- en: '[3] Sutskever, Ilya, James Martens, and Geoffrey E. Hinton. [“Generating text
    with recurrent neural networks.”](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf)
    Proc. of the 28th Intl. Conf. on Machine Learning (ICML). 2011.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Sutskever, Ilya, James Martens, and Geoffrey E. Hinton. [“使用循环神经网络生成文本。”](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf)
    2011年第28届国际机器学习会议论文集（ICML）。'
- en: '[4] Liwicki, Marcus, et al. [“A novel approach to on-line handwriting recognition
    based on bidirectional long short-term memory networks.”](http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf)
    Proc. of 9th Intl. Conf. on Document Analysis and Recognition. 2007.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Liwicki, Marcus等人。[“基于双向长短期记忆网络的在线手写识别的新方法。”](http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf)
    第9届国际文件分析与识别会议论文集。2007年。'
- en: '[5] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. [“Deep learning.”](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf)
    Nature 521.7553 (2015): 436-444.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] LeCun, Yann，Yoshua Bengio和Geoffrey Hinton。[“深度学习。”](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf)
    自然杂志521.7553（2015）：436-444。'
- en: '[6] Hochreiter, Sepp, and Jurgen Schmidhuber. [“Long short-term memory.”](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)
    Neural computation 9.8 (1997): 1735-1780.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Hochreiter, Sepp和Jurgen Schmidhuber。[“长短期记忆。”](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)
    神经计算9.8（1997）：1735-1780。'
- en: '[7] Cho, Kyunghyun. et al. [“Learning phrase representations using RNN encoder-decoder
    for statistical machine translation.”](https://arxiv.org/pdf/1406.1078.pdf) Proc.
    Conference on Empirical Methods in Natural Language Processing 1724–1734 (2014).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Cho, Kyunghyun等人。[“使用RNN编码器-解码器学习短语表示进行统计机器翻译。”](https://arxiv.org/pdf/1406.1078.pdf)
    2014年经验方法自然语言处理会议论文集1724-1734。'
- en: '[8] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. [“Reducing the dimensionality
    of data with neural networks.”](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)
    science 313.5786 (2006): 504-507.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Hinton, Geoffrey E.和Ruslan R. Salakhutdinov。[“利用神经网络降低数据的维度。”](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)
    科学313.5786（2006）：504-507。'
- en: '[9] Silver, David, et al. [“Mastering the game of Go with deep neural networks
    and tree search.”](http://web.iitd.ac.in/~sumeet/Silver16.pdf) Nature 529.7587
    (2016): 484-489.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Silver, David等人。[“利用深度神经网络和树搜索掌握围棋游戏。”](http://web.iitd.ac.in/~sumeet/Silver16.pdf)
    自然杂志529.7587（2016）：484-489。'
- en: '[10] Goodfellow, Ian, et al. [“Generative adversarial nets.”](https://arxiv.org/pdf/1406.2661.pdf)
    NIPS, 2014.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Goodfellow, Ian等人。[“生成对抗网络。”](https://arxiv.org/pdf/1406.2661.pdf) NIPS，2014年。'
