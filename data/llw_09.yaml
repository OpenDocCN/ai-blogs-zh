- en: 'Learning with not Enough Data Part 3: Data Generation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习不足的情况下使用的数据生成第3部分
- en: 原文：[https://lilianweng.github.io/posts/2022-04-15-data-gen/](https://lilianweng.github.io/posts/2022-04-15-data-gen/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://lilianweng.github.io/posts/2022-04-15-data-gen/](https://lilianweng.github.io/posts/2022-04-15-data-gen/)
- en: 'Here comes the Part 3 on learning with not enough data (Previous: [Part 1](https://lilianweng.github.io/posts/2021-12-05-semi-supervised/)
    and [Part 2](https://lilianweng.github.io/posts/2022-02-20-active-learning/)).
    Let’s consider two approaches for generating synthetic data for training.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是关于学习不足数据的第3部分（之前：[第1部分](https://lilianweng.github.io/posts/2021-12-05-semi-supervised/)和[第2部分](https://lilianweng.github.io/posts/2022-02-20-active-learning/)）。让我们考虑两种用于生成合成数据进行训练的方法。
- en: '**Augmented data**. Given a set of existing training samples, we can apply
    a variety of augmentation, distortion and transformation to derive new data points
    without losing the key attributes. We have covered a bunch of augmentation methods
    on text and images in a [previous post](https://lilianweng.github.io/posts/2021-05-31-contrastive/)
    on contrastive learning. For the sake of post completeness, I *duplicate* the
    section on data augmentation here with some edits.'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强数据**。给定一组现有的训练样本，我们可以应用各种增强、失真和转换来推导出新的数据点，而不会丢失关键属性。我们在一篇[先前的帖子](https://lilianweng.github.io/posts/2021-05-31-contrastive/)中涵盖了关于文本和图像的一堆增强方法。为了帖子的完整性，我在这里*复制*了关于数据增强的部分，并进行了一些编辑。'
- en: '**New data**. Given few or even no data points, we can rely on powerful pretrained
    models to generate a number of *new* data points. This is especially true in recent
    years given the fast progress in large pretrained [language models (LM)](https://lilianweng.github.io/posts/2019-01-31-lm/).
    Few shot prompting is shown to be effective for LM to learn within context without
    extra training.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新数据**。即使只有少量甚至没有数据点，我们也可以依靠强大的预训练模型生成一些*新*数据点。尤其是在最近几年，由于大型预训练[语言模型（LM）](https://lilianweng.github.io/posts/2019-01-31-lm/)的快速进展，这一点尤为明显。Few
    shot prompting已被证明对LM学习在上下文中没有额外训练是有效的。'
- en: Data Augmentation
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据增强
- en: The goal of data augmentation is to modify the input format (e.g. text wording,
    visual appearance) while the semantic meaning stays unchanged.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强的目标是修改输入格式（例如文本措辞，视觉外观），同时语义含义保持不变。
- en: Image Augmentation
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像增强
- en: Basic Image Processing Operations
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本图像处理操作
- en: There are several ways to modify an image while retaining its semantic information.
    We can use any one of the following augmentation or a composition of multiple
    operations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以修改图像而保留其语义信息。我们可以使用以下任何一种增强或多个操作的组合。
- en: Random cropping and then resize back to the original size.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机裁剪然后调整回原始大小。
- en: Random color distortions
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机颜色失真
- en: Random Gaussian blur
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机高斯模糊
- en: Random color jittering
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机颜色抖动
- en: Random horizontal flip
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机水平翻转
- en: Random grayscale conversion
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机灰度转换
- en: And many more. Check [PIL.ImageOps](https://pillow.readthedocs.io/en/stable/reference/ImageOps.html)
    for inspiration.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有更多。查看[PIL.ImageOps](https://pillow.readthedocs.io/en/stable/reference/ImageOps.html)以获取灵感。
- en: Task-Specific Augmentation Strategies
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务特定的增强策略
- en: If the downstream task is known, it is possible to learn the optimal augmentation
    strategies (i.e. what processing operations to use and how to combine them in
    sequence) to maximize the downstream task performance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已知下游任务，可以学习最佳的增强策略（即使用哪些处理操作以及如何组合它们以最大化下游任务性能）。
- en: '[*AutoAugment*](https://lilianweng.github.io/posts/2019-05-05-domain-randomization/#AutoAugment)
    ([Cubuk, et al. 2018](https://arxiv.org/abs/1805.09501)) is inspired by [neural
    architecture search](https://lilianweng.github.io/posts/2020-08-06-nas/), AutoAugment
    frames the problem of learning best data augmentation operations (i.e. shearing,
    rotation, invert, etc.) for image classification as an RL problem and looks for
    the combination that leads to the highest accuracy on the evaluation set. AutoAugment
    can be executed in adversarial fashion ([Zhang, et al 2019](https://arxiv.org/abs/1912.11188)).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*AutoAugment*](https://lilianweng.github.io/posts/2019-05-05-domain-randomization/#AutoAugment)（[Cubuk等，2018](https://arxiv.org/abs/1805.09501)）受到[神经架构搜索](https://lilianweng.github.io/posts/2020-08-06-nas/)的启发，AutoAugment将学习最佳数据增强操作（即剪切、旋转、反转等）的问题框架为图像分类的RL问题，并寻找导致评估集上最高准确性的组合。AutoAugment可以以对抗方式执行（[Zhang等，2019](https://arxiv.org/abs/1912.11188)）。'
- en: '*RandAugment* ([Cubuk et al., 2019](https://arxiv.org/abs/1909.13719)) greatly
    reduces the search space of AutoAugment by controlling the magnitudes of different
    transformation operations with a single magnitude parameter.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*RandAugment*（[Cubuk等，2019](https://arxiv.org/abs/1909.13719)）通过控制单个幅度参数来控制不同转换操作的幅度，大大减少了AutoAugment的搜索空间。'
- en: '*Population based augmentation* (PBA; [Ho et al., 2019](https://arxiv.org/abs/1905.05393))
    combines PBT (“population based training”; [Jaderberg et al, 2017](https://arxiv.org/abs/1711.09846))
    with AutoAugment, using the evolutionary algorithm to train a population of children
    models in parallel to evolve the best augmentation strategies.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于种群的增强*（PBA；[何等，2019](https://arxiv.org/abs/1905.05393)）将PBT（“基于种群的训练”；[Jaderberg等，2017](https://arxiv.org/abs/1711.09846)）与AutoAugment结合起来，使用进化算法并行训练一组子模型以演化出最佳的增强策略。'
- en: '*Unsupervised Data Augmentation* (UDA; [Xie et al., 2019](https://arxiv.org/abs/1904.12848)),
    among a set of possible augmentation strategies, selects a subset to minimize
    the KL divergence between the predicted distribution over an unlabelled example
    and its unlabelled augmented version.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无监督数据增强*（UDA；[谢等，2019](https://arxiv.org/abs/1904.12848)）在一组可能的增强策略中，选择一个子集以最小化未标记示例及其未标记增强版本之间的KL散度。'
- en: Image Mixture
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像混合
- en: Image mixture methods can construct new training examples from existing data
    points.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图像混合方法可以从现有数据点构建新的训练示例。
- en: '*Mixup* ([Zhang et al., 2018](https://arxiv.org/abs/1710.09412)) runs global-level
    mixture by creating a weighted pixel-wise combination of two existing images $I_1$
    and $I_2$: $I_\text{mixup} \gets \alpha I_1 + (1-\alpha) I_2$ and $\alpha \in
    [0, 1]$.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Mixup*（[张等，2018](https://arxiv.org/abs/1710.09412)）通过创建两个现有图像$I_1$和$I_2$的加权像素级组合来进行全局级别的混合：$I_\text{mixup}
    \gets \alpha I_1 + (1-\alpha) I_2$，其中$\alpha \in [0, 1]$。'
- en: '*Cutmix* ([Yun et al., 2019](https://arxiv.org/abs/1905.04899)) does region-level
    mixture by generating a new example by combining a local region of one image with
    the rest of the other image. $I_\text{cutmix} \gets \mathbf{M}_b \odot I_1 + (1-\mathbf{M}_b)
    \odot I_2$, where $\mathbf{M}_b \in \{0, 1\}^I$ is a binary mask and $\odot$ is
    element-wise multiplication. It is equivalent to filling the *cutout* ([DeVries
    & Taylor 2017](https://arxiv.org/abs/1708.04552)) region with the same region
    from another image.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Cutmix*（[尹等，2019](https://arxiv.org/abs/1905.04899)）通过将一个图像的局部区域与另一个图像的其余部分结合生成一个新示例。$I_\text{cutmix}
    \gets \mathbf{M}_b \odot I_1 + (1-\mathbf{M}_b) \odot I_2$，其中$\mathbf{M}_b \in
    \{0, 1\}^I$是一个二进制掩码，$\odot$是逐元素乘法。它等同于用另一个图像的相同区域填充*cutout*（[DeVries＆Taylor 2017](https://arxiv.org/abs/1708.04552)）区域。'
- en: Given a query $\mathbf{q}$, *MoCHi* (“mixing of contrastive hard negatives”;
    [Kalantidis et al. 2020](https://arxiv.org/abs/2010.01028)) maintains a queue
    of $K$ negative features $Q={\mathbf{n}_1, \dots, \mathbf{n}_K }$ and sorts these
    negative features by similarity to the query, $\mathbf{q}^\top \mathbf{n}$, in
    descending order. The first $N$ items in the queue are considered as the hardest
    negatives, $Q^N$. Then synthetic hard examples can be generated by $\mathbf{h}
    = \tilde{\mathbf{h}} / |\tilde{\mathbf{h}}|_2$ where $\tilde{\mathbf{h}} = \alpha\mathbf{n}_i
    + (1-\alpha) \mathbf{n}_j$ and $\alpha \in (0, 1)$. Even harder examples can be
    created by mixing with the query feature, $\mathbf{h}’ = \tilde{\mathbf{h}’} /
    |\tilde{\mathbf{h}’}|_2$ where $\tilde{\mathbf{h}’} = \beta\mathbf{q} + (1-\beta)
    \mathbf{n}_j$ and $\beta \in (0, 0.5)$.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个查询$\mathbf{q}$，*MoCHi*（“对比硬负例的混合”；[Kalantidis等，2020](https://arxiv.org/abs/2010.01028)）维护一个由$K$个负特征$Q={\mathbf{n}_1,
    \dots, \mathbf{n}_K }$组成的队列，并按照与查询的相似性$\mathbf{q}^\top \mathbf{n}$降序排序这些负特征。队列中的前$N$个项目被视为最难的负例，$Q^N$。然后可以通过$\mathbf{h}
    = \tilde{\mathbf{h}} / |\tilde{\mathbf{h}}|_2$生成合成的硬例，其中$\tilde{\mathbf{h}} =
    \alpha\mathbf{n}_i + (1-\alpha) \mathbf{n}_j$，$\alpha \in (0, 1)$。甚至可以通过与查询特征混合来创建更难的例子，$\mathbf{h}’
    = \tilde{\mathbf{h}’} / |\tilde{\mathbf{h}’}|_2$，其中$\tilde{\mathbf{h}’} = \beta\mathbf{q}
    + (1-\beta) \mathbf{n}_j$，$\beta \in (0, 0.5)$。
- en: Text Augmentation
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本增强
- en: Lexical Edits
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词汇编辑
- en: '*Easy Data Augmentation* (EDA; [Wei & Zou 2019](https://arxiv.org/abs/1901.11196))
    defines a set of simple but powerful operations for text augmentation. Given a
    sentence, EDA randomly chooses and applies one of four simple operations:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*简单数据增强*（EDA；[魏＆邹，2019](https://arxiv.org/abs/1901.11196)）为文本增强定义了一组简单但强大的操作。给定一个句子，EDA随机选择并应用四种简单操作中的一种：'
- en: 'Synonym replacement (SR): Replace $n$ random non-stop words with their synonyms.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同义词替换（SR）：用其同义词替换$n$个随机非停用词。
- en: 'Random insertion (RI): Place a random synonym of a randomly selected non-stop
    word in the sentence at a random position.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机插入（RI）：在句子中的随机位置放置一个随机选择的非停用词的同义词。
- en: 'Random swap (RS): Randomly swap two words and repeat $n$ times.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机交换（RS）：随机交换两个单词并重复$n$次。
- en: 'Random deletion (RD): Randomly delete each word in the sentence with probability
    $p$.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机删除（RD）：以概率$p$随机删除句子中的每个单词。
- en: where $p=\alpha$ and $n=\alpha \times \text{sentence_length}$, with the intuition
    that longer sentences can absorb more noise while maintaining the original label.
    The hyperparameter $\alpha$ roughly indicates the percent of words in one sentence
    that may be changed by one augmentation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$p=\alpha$且$n=\alpha \times \text{sentence_length}$，直觉上，较长的句子可以吸收更多噪音，同时保持原始标签。超参数$\alpha$大致表示一句话中可能被一个增强改变的单词的百分比。
- en: EDA is shown to improve the classification accuracy on several classification
    benchmark datasets compared to baseline without EDA. The performance lift is more
    significant on a *smaller* training set. All the four operations in EDA help improve
    the classification accuracy, but get to optimal at different $\alpha$’s.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: EDA已被证明在几个分类基准数据集上提高了分类准确性，与没有EDA的基准相比。在*较小*的训练集上，性能提升更为显著。EDA中的四种操作都有助于提高分类准确性，但在不同的$\alpha$值下达到最佳。
- en: '![](../Images/677041226462de35459d7cb233084359.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/677041226462de35459d7cb233084359.png)'
- en: 'Fig. 1\. EDA leads to performance improvement on several classification benchmarks.
    (Image source: [Wei & Zou 2019](https://arxiv.org/abs/1901.11196))'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. EDA导致几个分类基准的性能提升。（图片来源：[Wei & Zou 2019](https://arxiv.org/abs/1901.11196)）
- en: '*Contextual* Augmentation ([Kobayashi, 2018](https://arxiv.org/abs/1805.06201))
    replaces word $w_i$ at position $i$ by sampling from a probability distribution
    learned by a bidirectional LM such as BERT, $p(.\mid S\setminus{w_i})$. In this
    way, the words are substituted by synonyms, or similar words suitable for the
    context. To guarantee such operations do not alter the labels, the LM is fit to
    be label-conditioned bidirectional LM. Conditional BERT (CBERT; [Xing Wu et al.
    2018](https://arxiv.org/abs/1812.06705)) extends BERT to predict masked tokens
    conditioned on the class label and can be used for contextual augmentation prediction.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*上下文*增强（[Kobayashi, 2018](https://arxiv.org/abs/1805.06201)）通过从双向LM（如BERT）学习的概率分布中采样，$p(.\mid
    S\setminus{w_i})$，将位置$i$处的单词$w_i$替换为同义词或适合上下文的类似单词。为确保这些操作不改变标签，LM被设计为标签条件的双向LM。条件BERT（CBERT；[Xing
    Wu等，2018](https://arxiv.org/abs/1812.06705)）将BERT扩展为在类别标签上预测掩码标记，并可用于上下文增强预测。'
- en: Back-translation
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回译
- en: '*Back-translation* produces augmented data by translating text samples to another
    language and then translating them back. The translation happens in two ways and
    both directions should have decent enough performance to avoid significant loss
    of semantic meaning.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*回译*通过将文本样本翻译成另一种语言，然后再翻译回来，产生增强数据。翻译以两种方式进行，两个方向都应具有足够良好的性能，以避免语义意义的显著损失。'
- en: Mix-up
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混合
- en: It is also possible to apply [*Mixup*](#image-mixture) to text ([Guo et al.
    2019](https://arxiv.org/abs/1905.08941)) but on the embedding space to obtain
    some performance gain. The proposed method relies on a specially designed model
    architecture to operate the prediction on the word or sentence embedding. Adding
    adversarial noise in the embedding space as a way of data augmentation is shown
    to improve the generalization of model training ([Zhu et al. 2019](https://arxiv.org/abs/1909.11764)).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以将[*Mixup*](#image-mixture)应用于文本（[Guo等，2019](https://arxiv.org/abs/1905.08941)），但是在嵌入空间中以获得一些性能增益。所提出的方法依赖于专门设计的模型架构，在单词或句子嵌入上进行预测。在嵌入空间中添加对抗性噪声作为数据增强的方法已被证明可以提高模型训练的泛化能力（[Zhu等，2019](https://arxiv.org/abs/1909.11764)）。
- en: Audio Augmentation
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频增强
- en: Here is a list of several commonly used audio data augmentation methods, operated
    on raw audio or spectrograms, summarized by [Wang & van den Oord (2021)](https://arxiv.org/abs/2103.06508).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一份由[Wang & van den Oord (2021)](https://arxiv.org/abs/2103.06508)总结的几种常用音频数据增强方法列表，操作在原始音频或频谱图上。
- en: '**Audio mixup.** Given two audio clips $\mathbf{x}_1$ and $\mathbf{x}_2$, the
    mixed-up version $\hat{\mathbf{x}} = \alpha \mathbf{x}_1 + (1-\alpha)\mathbf{x}_2$
    should be associated with the label of the more dominant input. The audio mixup
    augments the data with more realistic noise.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**音频混合。** 给定两个音频剪辑$\mathbf{x}_1$和$\mathbf{x}_2$，混合版本$\hat{\mathbf{x}} = \alpha
    \mathbf{x}_1 + (1-\alpha)\mathbf{x}_2$应该与更主导的输入标签相关联。音频混合通过更真实的噪声增强数据。'
- en: '**Time masking.** A small consecutive chunk of the audio can be masked without
    losing semantic information.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间屏蔽。** 可以屏蔽音频的一个小连续块，而不会丢失语义信息。'
- en: '**Frequency masking.** A small amount of frequency components on the spectrogram
    can be dropped off and it should not change the associated label.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**频率屏蔽。** 频谱图上的少量频率分量可以被删除，而不应改变相关联的标签。'
- en: '**Frequency shift.** The spectrogram can be shifted by an integer between $[-F,
    F]$, where $F$ is the maximum shift size. It is a cheap augmentation to change
    the pitch of the audio.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**频率偏移。** 频谱图可以通过介于$[-F, F]$之间的整数进行偏移，其中$F$是最大偏移量。这是一种廉价的增强方法，可以改变音频的音调。'
- en: Architectural Augmentation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构增强
- en: Models with **dropout** layers can create augmented samples by applying different
    dropout masks on the same input sample. For example, in the contrastive learning
    model [*SimCSE*](https://lilianweng.github.io/posts/2021-05-31-contrastive/#simcse)
    ([Guo et al. 2021](https://arxiv.org/abs/2104.08821)), a sample is simply fed
    into the encoder twice with different dropout masks and these two versions are
    the positive pair where the other in-batch samples are considered as negative
    pairs.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 具有**dropout**层的模型可以通过在相同输入样本上应用不同的dropout掩码来创建增强样本。例如，在对比学习模型[*SimCSE*](https://lilianweng.github.io/posts/2021-05-31-contrastive/#simcse)（[郭等人，2021](https://arxiv.org/abs/2104.08821)）中，一个样本只需使用两个不同的dropout掩码两次输入到编码器中，这两个版本是正样本对，而其他批内样本被视为负样本对。
- en: Dropout augments data by adding noise onto the internal representation of the
    model. It can be applied in a more structured way, such as in **cutoff** ([Shen
    et al. (2020)](https://arxiv.org/abs/2009.13818)), where random chunks of the
    token embedding matrix are removed.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout通过向模型的内部表示添加噪声来增强数据。它可以以更有结构的方式应用，例如在**cutoff**（[沈等人（2020）](https://arxiv.org/abs/2009.13818)）中，随机删除令牌嵌入矩阵的随机块。
- en: Data Synthesis
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据合成
- en: Given that generating high-quality, photorealistic images is a lot more difficult
    than generating human-like natural language text and recent success with large
    pretrained language models, this section only focuses on text generation. To read
    more on how to synthesize realistic images, check posts on [GAN](https://lilianweng.github.io/posts/2017-08-20-gan/),
    [VAE](https://lilianweng.github.io/posts/2018-08-12-vae/), [flow](https://lilianweng.github.io/posts/2018-10-13-flow-models/)
    and [diffusion](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)
    models.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于生成高质量、逼真的图像比生成类似人类自然语言文本更困难，并且最近大型预训练语言模型取得了成功，本节仅关注文本生成。要了解如何合成逼真图像，请查看关于[GAN](https://lilianweng.github.io/posts/2017-08-20-gan/)、[VAE](https://lilianweng.github.io/posts/2018-08-12-vae/)、[flow](https://lilianweng.github.io/posts/2018-10-13-flow-models/)和[diffusion](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)模型的帖子。
- en: Language Model as Noisy Annotator
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言模型作为嘈杂标注者
- en: '[Wang et al. (2021)](https://arxiv.org/abs/2108.13487) explored ways to leverage
    GPT-3 as a weak annotator via few-shot prompting, achieving 10x cheaper than human
    labeling. The paper argues that by using data labeled by GPT-3, it essentially
    performs [*self-training*](https://lilianweng.github.io/posts/2021-12-05-semi-supervised/#self-training):
    The predictions on unlabeled samples apply entropy regularization on the model
    to avoid high class overlaps so as to help improve the model performance.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[王等人（2021）](https://arxiv.org/abs/2108.13487) 探索了通过少样本提示利用 GPT-3 作为弱标注者的方法，实现比人工标注便宜10倍。该论文认为，通过使用由
    GPT-3 标记的数据，实质上执行了[*自训练*](https://lilianweng.github.io/posts/2021-12-05-semi-supervised/#self-training)：对未标记样本的预测对模型施加熵正则化，以避免高类别重叠，从而帮助提高模型性能。'
- en: '![](../Images/96e873dbc9952edfdb0786e1a7fe9bb6.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96e873dbc9952edfdb0786e1a7fe9bb6.png)'
- en: 'Fig. 2\. Illustration of how to use GPT-3 to generate more training data with
    the human-in-the-loop active learning pipeline to improve the data quality. (Image
    source: [Wang et al. 2021](https://arxiv.org/abs/2108.13487))'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图2。展示如何使用 GPT-3 通过人在循环主动学习管道生成更多训练数据，以提高数据质量。 (图片来源：[王等人，2021](https://arxiv.org/abs/2108.13487))
- en: GPT-3-labeled samples selected by [active learning](https://lilianweng.github.io/posts/2022-02-20-active-learning/)
    with highest uncertainty are sent to human labelers to be re-annotated. The few-shot
    prompt contains a small number of human labeled examples and thus the labeling
    cost is restricted. Synthetic samples are ranked by predicted logits of label
    $y$ and those with the lowest scores go through relabeling.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过[主动学习](https://lilianweng.github.io/posts/2022-02-20-active-learning/)选择的
    GPT-3 标注样本中最不确定的样本被发送给人类标注者重新注释。Few-shot 提示包含少量人类标记的示例，因此标注成本受限。合成样本按标签 $y$ 的预测
    logits 排名，得分最低的样本经过重新标注。
- en: GPT-3 labeling achieves better results in the low-cost regime, but has a gap
    with human labeling when enough money is spent on data collection. This implies
    the following inequation, although to what extent “a lot” or “noisy” means depends
    on the task details.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 标注在低成本范围内取得更好的结果，但在数据收集上花费足够的资金时与人类标注存在差距。这意味着以下不等式，尽管“很多”或“嘈杂”到什么程度取决于任务细节。
- en: '**A lot of high-quality data > A lot of noisy data > A little high quality
    data**.'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**大量高质量数据 > 大量嘈杂数据 > 少量高质量数据**。'
- en: '![](../Images/073600eee09014ec9917207f9ba31140.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/073600eee09014ec9917207f9ba31140.png)'
- en: 'Fig. 3\. GPT-3 labeling technique improves the classification performance in
    the low-cost regime. (Image source: [Wang et al. 2021](https://arxiv.org/abs/2108.13487))'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. GPT-3 标注技术改善了低成本范围内的分类性能。（图片来源：[Wang 等人 2021](https://arxiv.org/abs/2108.13487)）
- en: Language Model as Data Generator
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言模型作为数据生成器
- en: If enough training dataset for text classification tasks are available, we can
    fine-tune language models to synthesize more training samples conditioned on labels
    ([Anaby-Tavor et al. 2019](https://arxiv.org/abs/1911.03118), [Kumar et al. 2021](https://arxiv.org/abs/2003.02245)).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果对文本分类任务有足够的训练数据集，我们可以微调语言模型以根据标签合成更多训练样本（[Anaby-Tavor 等人 2019](https://arxiv.org/abs/1911.03118)，[Kumar
    等人 2021](https://arxiv.org/abs/2003.02245)）。
- en: '*Language-model-based data augmentation* (**LAMBADA**; [Anaby-Tavor et al.
    2019](https://arxiv.org/abs/1911.03118)) takes such an idea, where the process
    involves fine-tuning both a classifier and a sample generation model.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*基于语言模型的数据增强*（**LAMBADA**；[Anaby-Tavor 等人 2019](https://arxiv.org/abs/1911.03118)）采用了这样一个想法，其中该过程涉及对分类器和样本生成模型进行微调。'
- en: 'Train a baseline classifier using the existing training dataset: $h = \mathcal{A}(\mathcal{D}_\text{train})$.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用现有的训练数据集训练基线分类器：$h = \mathcal{A}(\mathcal{D}_\text{train})$。
- en: Independently of step 1, a LM $\mathcal{M}$ is fine-tuned on $\mathcal{D}_{\text{train}}$
    to obtain $\mathcal{M}_{\text{tuned}}$.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 独立于步骤1，对 LM $\mathcal{M}$ 在 $\mathcal{D}_{\text{train}}$ 上进行微调，得到 $\mathcal{M}_{\text{tuned}}$。
- en: Synthesize a labeled dataset $\mathcal{D}^*$ by generating the continuation
    of the sequence `y[SEP]` until `EOS` using $\mathcal{M}_\text{tuned}$.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用 $\mathcal{M}_\text{tuned}$ 生成序列 `y[SEP]` 直到 `EOS` 的延续来合成标记数据集 $\mathcal{D}^*$。
- en: Filter synthesized dataset by,
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下方式筛选合成数据集，
- en: (1) Verifying that the predicted label is correct $h(x)=y$;
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: （1）验证预测的标签是否正确 $h(x)=y$；
- en: (2) Selecting the top ranked samples when they are ranked by the classifier
    probability. $\mathcal{D}_\text{syn} \subset \mathcal{D}^*$. They generate 10x
    more samples needed for augmentation and only the top 10% synthesized samples
    with highest confidence scores remain.
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: （2）当样本按分类器概率排名时，选择排名靠前的样本。$\mathcal{D}_\text{syn} \subset \mathcal{D}^*$。它们生成了需要增强的样本的10倍，并且只保留了置信度最高的前10%的合成样本。
- en: The final classifier is trained on $\mathcal{D}_\text{syn} \cup \mathcal{D}_\text{train}$
    . The process can be repeated multiple times, but it is unclear whether the benefit
    would quickly diminish or the repetitive process would bring in self-bias.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最终分类器在 $\mathcal{D}_\text{syn} \cup \mathcal{D}_\text{train}$ 上进行训练。该过程可以多次重复，但不清楚好处是否会迅速减少或重复过程是否会带来自我偏见。
- en: '![](../Images/c0f2a471163a458c37c42a5aa17cbbd2.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0f2a471163a458c37c42a5aa17cbbd2.png)'
- en: 'Fig. 4\. Accuracy of LAMBADA vs. other generative approaches over all datasets
    and classifiers. (Image source: [Anaby-Tavor et al. 2019](https://arxiv.org/abs/1911.03118))'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图4. LAMBADA 的准确性与其他生成方法在所有数据集和分类器上的比较。（图片来源：[Anaby-Tavor 等人 2019](https://arxiv.org/abs/1911.03118)）
- en: To simplify LAMBADA, we can actually remove the dependency of a fine-tuned generation
    model and an existing training dataset of a decent size ([Step 2](#step2) above).
    *Unsupervised data generation* (**UDG**; [Wang et al. 2021](https://arxiv.org/abs/2109.09193))
    relies on few-shot prompting on a large pretrained language model to generate
    high-quality synthetic data for training. Opposite to the above approach where
    LM is asked to predict $y$ given $\mathbf{x}$, UDG instead synthetizes the inputs
    $\mathbf{x}$ given labels $y$. Then a task-specific model is trained on this synthetic
    dataset.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化 LAMBADA，我们实际上可以消除精调生成模型和具有相当规模的现有训练数据集的依赖（[上述步骤 2](#step2)）。*无监督数据生成*（**UDG**；[Wang
    等人，2021](https://arxiv.org/abs/2109.09193)）依赖于对大型预训练语言模型进行少样本提示，以生成高质量的合成数据进行训练。与上述方法相反，其中
    LM 被要求在给定 $\mathbf{x}$ 的情况下预测 $y$，UDG 反之，合成输入 $\mathbf{x}$ 给定标签 $y$。然后在这个合成数据集上训练一个任务特定模型。
- en: '[Schick & Schutze (2021)](https://arxiv.org/abs/2104.07540) proposed a similar
    idea but on the NLI task instead of classification, asking PLM to write sentence
    pairs that are similar or different while the model is prompted with task-specific
    instructions.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[Schick & Schutze（2021）](https://arxiv.org/abs/2104.07540) 提出了一个类似的想法，但是在 NLI
    任务上而不是分类任务上，要求 PLM 在提示任务特定指令的情况下编写相似或不同的句子对。'
- en: '![](../Images/07fd109c117efd7a696a8a97d6839426.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07fd109c117efd7a696a8a97d6839426.png)'
- en: 'Fig. 5\. Illustration of the unsupervised data generation (UDG) framework.
    (Image source: [Wang et al., 2021](https://arxiv.org/abs/2109.09193))'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 无监督数据生成（UDG）框架的示意图。 (图片来源：[Wang 等人，2021](https://arxiv.org/abs/2109.09193))
- en: 'The few-shot prompts of UDG contain a small number of unlabeled examples, as
    well as a task-specific natural language description of the desired label. Because
    some generated examples are noisy, they implemented **noisy label annealing**
    (**NLA**) techniques to filter potentially misaligned samples out during the training
    processes. NLA gradually removes noisy training signals in time during training
    when the model starts to disagree with its pseudo label with high confidence.
    At each training step $t$, a given example $(\mathbf{x}_i, \hat{y}_i)$ is considered
    noisy and should be removed if:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: UDG 的少样本提示包含少量未标记示例，以及所需标签的任务特定自然语言描述。由于一些生成的示例存在噪声，他们实施了**噪声标签退火**（**NLA**）技术，在训练过程中过滤潜在的不对齐样本。在训练过程中，当模型开始与其伪标签高度不一致时，NLA
    会逐渐在时间上去除嘈杂的训练信号。在每个训练步骤 $t$，如果给定示例 $(\mathbf{x}_i, \hat{y}_i)$ 被认为是嘈杂的并且应该被移除，则：
- en: The model predicted probability is higher than a threshold $p(\bar{y}_i \vert
    \mathbf{x}_i) > \mu_t$ where $\bar{y}_i = \arg\max_y p(y \vert \mathbf{x}_i)$;
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型预测的概率高于阈值 $p(\bar{y}_i \vert \mathbf{x}_i) > \mu_t$，其中 $\bar{y}_i = \arg\max_y
    p(y \vert \mathbf{x}_i)$；
- en: And the predicted label is different from the synthetic label, $\bar{y}_i \neq
    \hat{y}_i$.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的标签与合成标签不同，$\bar{y}_i \neq \hat{y}_i$。
- en: Note that the threshold $\mu_t$ is time-dependent, initialized as 0.9 and then
    gradually annealed to $1/\text{num_of_classes}$ in time.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，阈值 $\mu_t$ 是时间相关的，初始化为 0.9，然后随时间逐渐退火至 $1/\text{num_of_classes}$。
- en: As shown in their experiments, the improvement of UDG over few-shot inference
    is quit significant, where NLA brings in some extra boost. The results are even
    comparable with supervised fine-tuning on several cases.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 正如他们的实验所示，UDG 相对于少样本推理的改进是相当显著的，NLA 带来了一些额外的提升。在几种情况下，结果甚至可以与监督微调相媲美。
- en: '![](../Images/e9e0ba69219d0b80045d5e5d2cdf31ca.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9e0ba69219d0b80045d5e5d2cdf31ca.png)'
- en: 'Fig. 6\. Comparison of accuracy of UDG and other methods on different classification
    datasets. (Image source: [Wang et al., 2021](https://arxiv.org/abs/2109.09193))'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6\. UDG 和其他方法在不同分类数据集上准确率的比较。 (图片来源：[Wang 等人，2021](https://arxiv.org/abs/2109.09193))
- en: '[Han et al (2021)](https://arxiv.org/abs/2110.05448) achieved SOTA results
    on translation tasks using few-shot data generation, distillation and back-translation.
    The proposed method contains the following steps, assuming no access to paired
    translation data:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[Han 等人（2021）](https://arxiv.org/abs/2110.05448) 在翻译任务上利用少样本数据生成、蒸馏和回译取得了 SOTA
    结果。提出的方法包括以下步骤，假设没有访问配对翻译数据：'
- en: '*Zero-shot Generation.* First use the zero-shot translation ability of a pre-trained
    LM to generate translations for a small set of unlabeled sentences.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*零-shot 生成*。首先利用预训练 LM 的零-shot 翻译能力为一小组未标记的句子生成翻译。'
- en: '*Few-shot Generation.* Then amplify these zero-shot translations by using them
    as few-shot demonstrations to gather an even larger synthetic dataset.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*少样本生成*。然后通过将它们用作少样本演示来放大这些零样本翻译，以收集更大的合成数据集。'
- en: '*Distillation.* Fine-tune the model on this dataset. The translation task is
    formulated as a language modeling task `[L1] <seq1> [[TRANSLATE]] [L2] <seq2>.`
    given a pair of two sequences `<seq1, seq2>` in two different languages. At test-time,
    the LM is prompted with `[L1] <seq> [[TRANSLATE]] [L2]` and a candidate translation
    `<sampledSeq>` is parsed from the sampled completion.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*蒸馏*。在这个数据集上对模型进行微调。翻译任务被制定为一个语言建模任务`[L1] <seq1> [[TRANSLATE]] [L2] <seq2>.`给定两种不同语言的两个序列`<seq1,
    seq2>`。在测试时，语言模型被提示为`[L1] <seq> [[TRANSLATE]] [L2]`，并且从采样完成中解析出一个候选翻译`<sampledSeq>`。'
- en: '*Back-translation.* Continue fine-tuning on the back-translation dataset where
    the order of samples is reversed, `<sampledSeq, seq>`.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*反向翻译*。在反向翻译数据集上继续微调，其中样本顺序被颠倒，`<sampledSeq, seq>`。'
- en: Step 1-4 can be repeated.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 步骤1-4可以重复。
- en: '![](../Images/719c463b079c7af6d86b5c0f5de91f9d.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/719c463b079c7af6d86b5c0f5de91f9d.png)'
- en: 'Fig. 7\. Algorithm of using distillation and back-translation to train a language
    model on translation tasks. (Image source: [Han et al. 2021](https://arxiv.org/abs/2110.05448))'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图7\. 使用蒸馏和反向翻译训练语言模型进行翻译任务的算法。 (图片来源：[Han等人，2021](https://arxiv.org/abs/2110.05448))
- en: The success of the above method depends on a good pretrained LM to kick off
    the initial translation dataset. Iterative few-shot generation and distillation
    with back-translation is an effective way to extract and refine the translation
    capability out of a pretrained LM and further to distill that into a new model.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法的成功取决于一个良好的预训练语言模型，以启动初始翻译数据集。通过反向翻译的迭代式少样本生成和蒸馏是从预训练语言模型中提取和精炼翻译能力的有效方式，进一步将其蒸馏到一个新模型中。
- en: '![](../Images/c75eb6fcc4760f13bce61679b1dfa15f.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c75eb6fcc4760f13bce61679b1dfa15f.png)'
- en: 'Fig. 8\. Comparison of BLEU scores of the translation models of different training
    runs using: only distillation, back-translation, both and with more monolingual
    training data. (Image source: [Han et al. 2021](https://arxiv.org/abs/2110.05448))'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图8\. 比较不同训练运行的翻译模型的BLEU分数，使用：仅蒸馏、反向翻译、两者以及更多单语训练数据。 (图片来源：[Han等人，2021](https://arxiv.org/abs/2110.05448))
- en: How to Quantify Generated Data Quality?
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何量化生成数据的质量？
- en: Given all the generated data, either by data augmentation or data synthesis,
    how can we quantify data quality in terms of how they improve model generalization?
    [Gontijo-Lopes et al. (2020)](https://arxiv.org/abs/2002.08973) introduced two
    dimensions to track, affinity and diversity.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于所有生成的数据，无论是通过数据增强还是数据合成，我们如何量化数据质量，以了解它们如何改善模型的泛化能力？[Gontijo-Lopes等人（2020）](https://arxiv.org/abs/2002.08973)引入了两个跟踪维度，亲和力和多样性。
- en: '**Affinity** is a model-sensitive metric for *distribution shift*, quantifying
    how much an augmentation shifts the training data distribution from what a model
    learned.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**亲和力**是一个对*分布偏移*敏感的度量，量化增强数据将训练数据分布从模型学习的内容偏移多少。'
- en: 'Definition: The performance difference between the model tested on clean data
    vs augmented data, while the model is trained on clean data.'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义：在模型在干净数据上测试与在干净数据上训练时的性能差异。
- en: As a comparison, KL can also measure distribution shift but does not consider
    the model performance.
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为比较，KL也可以衡量分布偏移，但不考虑模型性能。
- en: '**Diversity** is a measure of *augmentation complexity*, measuring the complexity
    of the augmented data with respect to the model and learning procedure.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样性**是*增强复杂性*的度量，衡量增强数据相对于模型和学习过程的复杂性。'
- en: 'Definition: The final training loss of a model trained with a given augmentation.'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义：使用给定增强训练的模型的最终训练损失。
- en: Another potential diversity measure is the entropy of the transformed data.
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个潜在的多样性度量是转换数据的熵。
- en: A third potential diversity measure is the training time needed for a model
    to reach a given training accuracy threshold.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个潜在的多样性度量是模型达到给定训练准确度阈值所需的训练时间。
- en: All three metrics above are correlated.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上述三个指标之间存在相关性。
- en: The final model performance is dependent on both metrics to be high enough.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最终模型的性能取决于这两个指标都足够高。
- en: '![](../Images/5f8139e632a71965509381fbbd2f0b69.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f8139e632a71965509381fbbd2f0b69.png)'
- en: 'Fig. 9\. (a) Left: A scatter plot of affinity vs diversity metric, where each
    point represents a different augmentation method and its color indicates the final
    test accuracy. (b) Right: The conceptual illustration of the relationship between
    clean and augmented data in different regions of affinity and diversity metrics.
    (Image source: [Gontijo-Lopes et al. 2020](https://arxiv.org/abs/2002.08973))'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. (a) 左图：亲和力与多样性度量的散点图，每个点代表不同的增强方法，颜色表示最终的测试准确度。(b) 右图：在不同亲和力和多样性度量区域中，干净数据和增强数据之间的关系的概念图示。
    (图片来源：[Gontijo-Lopes et al. 2020](https://arxiv.org/abs/2002.08973))
- en: There are many quantitative metrics on relevancy and diversity, in different
    formations depending on whether a reference is available, such as perplexity,
    BLEU for text and inception score for images. I’m skipping the list of concrete
    quantitative metrics on quality here, given it could be very long.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多关于相关性和多样性的定量度量，根据是否有参考文献，形式各异，例如文本的困惑度、BLEU以及图像的Inception分数。这里我跳过了关于质量的具体定量度量的列表，因为它可能会很长。
- en: Training with Noisy Data
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用嘈杂数据进行训练
- en: It is convenient to collect a large amount of noisy data via model generation
    or data augmentation, but it is hard to guarantee that augmented and generated
    data can be 100% accurate. Knowing that deep neural networks can easily overfit
    noisy labels and “memotize” corrupted labels, we can apply the techniques for
    training on noisy labels (*noise-robust training*) when using generated data to
    stabilize and optimize the performance. Please check this [survey paper (Song
    et al. 2021)](https://arxiv.org/abs/2007.08199) on learning from noisy labels
    for a more thorough coverage of related work.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模型生成或数据增强方便地收集大量嘈杂数据，但很难保证增强和生成的数据能够100%准确。深度神经网络很容易过拟合嘈杂标签并“记忆”损坏的标签，因此在使用生成的数据时，我们可以应用训练嘈杂标签的技术（*噪声鲁棒训练*）来稳定和优化性能。请查看这篇关于从嘈杂标签中学习的[调查论文（Song
    et al. 2021）](https://arxiv.org/abs/2007.08199)以更全面地了解相关工作。
- en: Regularization and Robust Architecture
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化和稳健架构
- en: Generally speaking, mechanisms designed for avoiding overfitting should help
    improve training robustness when working with moderately noisy data, such as weight
    decay, dropout, batch normalization. In fact, good data augmentation (i.e. only
    non-essential attributes are modified) can be considered as a way of regularization
    as well.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，为了避免过拟合而设计的机制在处理适度嘈杂数据时应该有助于提高训练的稳健性，例如权重衰减、dropout、批归一化。事实上，良好的数据增强（即仅修改非必要属性）也可以被视为一种正则化的方式。
- en: A different approach is to enhance the network with a dedicated **noisy adaptation
    layer** to approximate the unknown projection of label corruption ([Sukhbaatar
    et al. 2015](https://arxiv.org/abs/1406.2080), [Goldberger & Ben-Reuven, 2017](https://openreview.net/forum?id=H12GRgcxg)).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是通过专门的**嘈杂适应层**来增强网络，以逼近标签损坏的未知投影（[Sukhbaatar et al. 2015](https://arxiv.org/abs/1406.2080)，[Goldberger
    & Ben-Reuven, 2017](https://openreview.net/forum?id=H12GRgcxg)）。
- en: '[Sukhbaatar et al. (2015)](https://arxiv.org/abs/1406.2080) introduced an extra
    linear layer $Q$ into the network architecture to adapt the predictions to match
    the noisy label distribution. The noise matrix $Q$ is initially *fixed* to the
    identity function while only the base model parameters is updated. After some
    time, $Q$ starts to be updated and expected to capture the noise in the data.
    The noise matrix is trained with regularization to encourage it to match the noise
    distribution while keeping the base model prediction accurate for true labels.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sukhbaatar et al. (2015)](https://arxiv.org/abs/1406.2080)在网络架构中引入了额外的线性层
    $Q$，以使预测与嘈杂标签分布匹配。噪声矩阵 $Q$ 最初被*固定*为单位函数，只有基础模型参数被更新。一段时间后，$Q$开始被更新，并期望捕捉数据中的噪声。噪声矩阵通过正则化进行训练，以鼓励其匹配噪声分布，同时保持基础模型对真实标签的准确预测。'
- en: '![](../Images/2e2a7a8955843fabaa626723d8801672.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e2a7a8955843fabaa626723d8801672.png)'
- en: 'Fig. 10\. (a) Left: A noise matrix $Q$ is added between softmax and the final
    output for the loss. (b) Right: The noise matrix $Q$ is fixed at the identity
    function initially and only gets updated with regularization after some training.
    (Image source: [Sukhbaatar et al. 2015](https://arxiv.org/abs/1406.2080))'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10\. (a) 左图：在 softmax 和最终输出之间添加了一个噪声矩阵 $Q$ 用于损失计算。(b) 右图：噪声矩阵 $Q$ 最初被固定为单位函数，只有在一定训练后才会随着正则化进行更新。(图片来源：[Sukhbaatar
    et al. 2015](https://arxiv.org/abs/1406.2080))
- en: However, it is hard to guarantee such a noise matrix layer would only capture
    the noise transition distribution and it is actually non-trivial to learn. [Goldberger
    & Ben-Reuven (2017)](https://openreview.net/forum?id=H12GRgcxg)) proposed to add
    an additional softmax layer end-to-end with the base model and apply the [EM algorithm](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)
    by treating the correct labels as latent random variable and the noise processes
    as a communication channel with unknown parameters.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，很难保证这样一个噪声矩阵层只捕捉噪声转换分布，实际上学习起来并不是一件简单的事情。[Goldberger & Ben-Reuven (2017)](https://openreview.net/forum?id=H12GRgcxg))
    提出了在基础模型的端到端添加一个额外的softmax层，并应用[EM算法](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)，将正确标签视为潜在随机变量，将噪声过程视为具有未知参数的通信通道。
- en: Robust Learning Objective
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 鲁棒学习目标
- en: Besides the most commonly used cross entropy loss, some other choices of learning
    objectives are shown to be more robust to noisy labels.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 除了最常用的交叉熵损失外，一些其他学习目标的选择被证明对嘈杂标签更具鲁棒性。
- en: For example, **MAE** (mean absolute error) is more robust to noisy labels than
    CCE (categorical cross entropy), as it treats every sample equally ([Ghosh et
    al. 2017](https://arxiv.org/abs/1712.09482)). Lack of different weighting among
    training samples of MAE lead to significantly longer training time. Motivated
    by the tradeoff between MAE and CCE, [Zhang & Sabuncu (2018)](https://arxiv.org/abs/1805.07836)
    proposed *generalized cross entropy* (**GCE**), a generalization of CCE loss to
    be robust to noisy data.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**MAE**（平均绝对误差）比CCE（分类交叉熵）对嘈杂标签更具鲁棒性，因为它平等对待每个样本（[Ghosh et al. 2017](https://arxiv.org/abs/1712.09482)）。MAE在训练样本之间缺乏不同的加权导致训练时间显著延长。受MAE和CCE之间的权衡启发，[Zhang
    & Sabuncu (2018)](https://arxiv.org/abs/1805.07836)提出了*广义交叉熵*（**GCE**），将CCE损失的泛化以适应嘈杂数据。
- en: 'To exploit the benefits of both the noise-robustness provided by MAE and the
    implicit weighting scheme of CCE, GCE adopts the the negative Box-Cox transformation
    as a loss function:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用MAE提供的抗噪性和CCE的隐式加权方案的好处，GCE采用了负的Box-Cox转换作为损失函数：
- en: $$ \mathcal{L}_q(f(\mathbf{x}_i, y_i = j)) = \frac{1 - f^{(j)}(\mathbf{x}_i)^q}{q}
    $$
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \mathcal{L}_q(f(\mathbf{x}_i, y_i = j)) = \frac{1 - f^{(j)}(\mathbf{x}_i)^q}{q}
    $$
- en: where $f^{(j)}$ denotes the $j$-th element of $f(.)$ and $q \in (0, 1]$. $\mathcal{L}_q$
    is equivalent to CCE when $q \to 0$ and becomes MAE when $q=1$. Empirical experiments
    show that there exists a threshold of $q$ with which overfitting never emerges
    and the noisier the data the higher such a threshold should be.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$f^{(j)}$表示$f(.)$的第$j$个元素，$q \in (0, 1]$。当$q \to 0$时，$\mathcal{L}_q$等同于CCE，当$q=1$时变为MAE。实证实验表明存在一个$q$的阈值，使得过拟合永远不会出现，数据越嘈杂，这种阈值就应该越高。
- en: Given true and predicted labels, $y_i, \hat{y}_i \in \{0, 1\}$ and let $u_i=y_i
    \cdot \hat{y}_i$, the **zero-one loss**, $\mathcal{L}_{01}(\mathbf{u}) = \sum_{i=1}^n
    \mathbb{1}[u_i < 0]$, is another learning subjective shown to be robust to noisy
    data. Minimizing the empirical risk with the zero-one loss is shown to be equivalent
    to minimizing the empirical adversarial (worse-case) risk ([Hu et al 2018](https://arxiv.org/abs/1611.02041)).
    Because the worst-case risk is the upper bound of the classification risk of the
    clean data distribution, minimizing the worst-case risk can lead to decreased
    true risk, which makes the zero-one loss especially robust. However, the zero-one
    loss is non-differentiable and cannot be optimized directly. One solution is to
    approximate an *upper bound* of the zero-one loss and to minimize the upper bound
    loss instead.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 给定真实和预测标签，$y_i, \hat{y}_i \in \{0, 1\}$，令$u_i=y_i \cdot \hat{y}_i$，**零一损失**，$\mathcal{L}_{01}(\mathbf{u})
    = \sum_{i=1}^n \mathbb{1}[u_i < 0]$，是另一种被证明对嘈杂数据具有鲁棒性的学习目标。通过最小化零一损失的经验风险等同于最小化经验对抗（最坏情况）风险（[Hu
    et al 2018](https://arxiv.org/abs/1611.02041)）。因为最坏情况风险是干净数据分布的分类风险的上界，最小化最坏情况风险可以导致真实风险的降低，这使得零一损失特别鲁棒。然而，零一损失是不可微的，不能直接优化。一种解决方案是近似零一损失的*上界*，并最小化上界损失。
- en: The [hinge loss](https://en.wikipedia.org/wiki/Hinge_loss), $\mathcal{L}_\text{hinge}(\mathbf{u})
    = \sum_{i=1}^n \max(0, 1 - u_i)$, defines a rough upper bound of the zero-one
    loss. [Lyu & Tsang (2020)](https://arxiv.org/abs/1905.10045) proposed a *curriculum
    loss* (**CL**), which is a tighter upper bound compared to a conventional surrogate
    loss like the hinge loss, $\mathcal{L}_\text{01}(\mathbf{u}) \leq \mathcal{L}_\text{CL}(\mathbf{u})
    \leq \mathcal{L}_\text{hinge}(\mathbf{u})$.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[铰链损失](https://en.wikipedia.org/wiki/Hinge_loss)，$\mathcal{L}_\text{hinge}(\mathbf{u})
    = \sum_{i=1}^n \max(0, 1 - u_i)$，定义了零一损失的一个粗略上界。[Lyu & Tsang (2020)](https://arxiv.org/abs/1905.10045)提出了一个*课程损失*（**CL**），它是一个比铰链损失等传统替代损失更紧的上界，$\mathcal{L}_\text{01}(\mathbf{u})
    \leq \mathcal{L}_\text{CL}(\mathbf{u}) \leq \mathcal{L}_\text{hinge}(\mathbf{u})$。'
- en: $$ \mathcal{L}_\text{CL}(\mathbf{u}) = \min_{\mathbf{w}\in\{0,1\}^n}\max(\sum_{i=1}^n
    w_i \ell(u_i), n - \sum_{i=1}^n w_i + \sum_{i=1}^n\mathbb{1}[u_i < 0]) $$
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \mathcal{L}_\text{CL}(\mathbf{u}) = \min_{\mathbf{w}\in\{0,1\}^n}\max(\sum_{i=1}^n
    w_i \ell(u_i), n - \sum_{i=1}^n w_i + \sum_{i=1}^n\mathbb{1}[u_i < 0]) $$
- en: where $\ell(u_i)$ is a base surrogate loss for the zero-one loss (e.g. hinge
    loss) and the optimal weighting variable $\mathbf{w}$ is to be learned.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\ell(u_i)$是零一损失的基本替代损失（例如铰链损失），最优加权变量$\mathbf{w}$是要学习的。
- en: 'Given a label corruption rate $\rho$, the *noise pruned curriculum loss* (**NPCL**)
    is constructed based on the intuition that an ideal model should correctly classify
    $n(1-\rho)$ samples with clean labels but misclassify $n\rho$ corrupted labels.
    If $\rho$ is a known prior, we would know how many samples (with largest losses)
    to be pruned. Assuming $\ell(u_1) \leq \dots \leq \ell(u_n)$, then $u_{n(1-\rho)+1}
    = \dots = u_n =0$ and the following NPCL is the basic CL for only $n(1-\rho)$
    samples:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 给定标签损坏率$\rho$，*噪声修剪课程损失*（**NPCL**）是基于这样的直觉构建的，即理想模型应该正确分类$n(1-\rho)$个带有干净标签的样本，但错误分类$n\rho$个损坏标签。如果$\rho$是一个已知的先验，我们将知道要修剪多少样本（具有最大损失）。假设$\ell(u_1)
    \leq \dots \leq \ell(u_n)$，那么$u_{n(1-\rho)+1} = \dots = u_n =0$，以下NPCL是仅针对$n(1-\rho)$个样本的基本CL：
- en: $$ \text{NPCL}(\mathbf{u}) = \min_{\mathbf{w}\in\{0,1\}^{n(1-\rho)}} \max(\sum_{i=1}^{n(1-\rho)}
    w_i \ell(u_i), n(1-\rho) - \sum_{i=1}^{n(1-\rho)} w_i) $$
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \text{NPCL}(\mathbf{u}) = \min_{\mathbf{w}\in\{0,1\}^{n(1-\rho)}} \max(\sum_{i=1}^{n(1-\rho)}
    w_i \ell(u_i), n(1-\rho) - \sum_{i=1}^{n(1-\rho)} w_i) $$
- en: When experimenting on CIFAR-10, NPCL is comparable with GCE and performs better
    when the noise rate increases.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在CIFAR-10上进行实验时，NPCL与GCE相当，并且在噪声率增加时表现更好。
- en: Label Correction
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标签校正
- en: Since it is known some labels are incorrect, noise-robust training can explicitly
    take the label correction into consideration.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由于已知一些标签是不正确的，噪声鲁棒训练可以明确考虑标签校正。
- en: One approach is to rely on the estimation of a noise transition matrix and use
    that to correct the forward or backward loss, named **F-correction** ([Patrini
    et al. 2017](https://arxiv.org/abs/1609.03683)). Let’s first assume that there
    are $k$ classes and the noise transition matrix $C \in [0, 1]^{k\times k}$ is
    observable and the label flipping probability does not depend on the sample input
    but only the label (i.e. known as random classification noise, RCN). Let $\tilde{y}$
    denote a corrupted label. Each entry of $C$ represents the probability of one
    label flipping to another^([1](#fn:1)),
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是依赖于噪声转移矩阵的估计，并使用它来纠正前向或后向损失，称为**F-correction**（[Patrini et al. 2017](https://arxiv.org/abs/1609.03683)）。让我们首先假设有$k$个类别和噪声转移矩阵$C
    \in [0, 1]^{k\times k}$是可观测的，标签翻转概率不依赖于样本输入而只依赖于标签（即被称为随机分类噪声，RCN）。让$\tilde{y}$表示一个损坏的标签。$C$的每个条目表示一个标签翻转为另一个的概率^([1](#fn:1))，
- en: $$ C_{ij} = p(\tilde{y}= j \vert y =i, \mathbf{x}) \approx p(\tilde{y}= j \vert
    y =i) $$
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: $$ C_{ij} = p(\tilde{y}= j \vert y =i, \mathbf{x}) \approx p(\tilde{y}= j \vert
    y =i) $$
- en: Then we can proceed a forward label correction procedure to incorporate the
    prior knowledge of noisy transition matrix into the prediction.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以进行前向标签校正过程，将嘈杂转移矩阵的先验知识纳入预测中。
- en: $$ \begin{aligned} \mathcal{L}(\hat{p}(\tilde{y}\vert\mathbf{x}), y) &= - \log
    \hat{p}(\tilde{y}=i\vert\mathbf{x}) \\ &= - \log \sum_{j=1}^k p(\tilde{y}=i\vert
    y=j) \hat{p}(y=j\vert\mathbf{x}) \\ &= - \log \sum_{j=1}^k C_{ji} \hat{p}(y=j\vert\mathbf{x})
    \end{aligned} $$
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \begin{aligned} \mathcal{L}(\hat{p}(\tilde{y}\vert\mathbf{x}), y) &= - \log
    \hat{p}(\tilde{y}=i\vert\mathbf{x}) \\ &= - \log \sum_{j=1}^k p(\tilde{y}=i\vert
    y=j) \hat{p}(y=j\vert\mathbf{x}) \\ &= - \log \sum_{j=1}^k C_{ji} \hat{p}(y=j\vert\mathbf{x})
    \end{aligned} $$
- en: In matrix form, we have $\mathcal{L}(\hat{p}(y \vert \mathbf{x})) = - \log C^\top
    \hat{p}(y \vert \mathbf{x})$. However, such a noise transition matrix is usually
    *unknown*. If we have access to a clean dataset, the noise matrix $C$ can be estimated
    ([Hendrycks et al. 2018](https://arxiv.org/abs/1802.05300)) by calculating confusion
    matrix on the clean data. Let’s denote a clean trusted dataset as $\mathcal{D}_c$
    and a noisy dataset as $\mathcal{D}_n$ going forward.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以矩阵形式，我们有 $\mathcal{L}(\hat{p}(y \vert \mathbf{x})) = - \log C^\top \hat{p}(y
    \vert \mathbf{x})$。然而，这样的噪声转移矩阵通常是*未知*的。如果我们可以访问一个干净数据集，噪声矩阵 $C$ 可以通过在干净数据上计算混淆矩阵来估计
    ([Hendrycks et al. 2018](https://arxiv.org/abs/1802.05300))。让我们将一个干净可信的数据集表示为
    $\mathcal{D}_c$，将一个嘈杂数据集表示为 $\mathcal{D}_n$。
- en: $$ \hat{C}_{ij} = \frac{1}{\vert \mathcal{A}_i\vert} \sum_{\mathbf{x} \in \mathcal{A}_i}
    \hat{p}(\tilde{y}=j \vert y=i, \mathbf{x}) \approx p(\tilde{y}=j \vert y=i) $$
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \hat{C}_{ij} = \frac{1}{\vert \mathcal{A}_i\vert} \sum_{\mathbf{x} \in \mathcal{A}_i}
    \hat{p}(\tilde{y}=j \vert y=i, \mathbf{x}) \approx p(\tilde{y}=j \vert y=i) $$
- en: where $\mathcal{A}_i$ is a subset of data points from $\mathcal{D}_c$ with label
    $i$.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 $\mathcal{A}_i$ 是来自带有标签 $i$ 的 $\mathcal{D}_c$ 数据点的子集。
- en: Let $f(x) = \hat{p}(\tilde{y} \vert \mathbf{x}; \theta)$ and this model should
    be trained with $\mathcal{L}(f(\mathbf{x}), y)$ on clean data $\mathcal{D}_c$
    and with $\mathcal{L}(\hat{C}^\top f(\mathbf{x}), \hat{y})$ on noisy data $\mathcal{D}_n$.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 令 $f(x) = \hat{p}(\tilde{y} \vert \mathbf{x}; \theta)$，这个模型应该在干净数据 $\mathcal{D}_c$
    上用 $\mathcal{L}(f(\mathbf{x}), y)$ 进行训练，并在嘈杂数据 $\mathcal{D}_n$ 上用 $\mathcal{L}(\hat{C}^\top
    f(\mathbf{x}), \hat{y})$ 进行训练。
- en: '![](../Images/279ebce48a0db388d915532c3ab1746b.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/279ebce48a0db388d915532c3ab1746b.png)'
- en: 'Fig. 11\. Algorithm of gold loss correction (GLC), estimating the noise transition
    matrix with a trusted dataset. (Image source: [Hendrycks et al. 2018](https://arxiv.org/abs/1802.05300))'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '图 11\. 金标准损失校正（GLC）算法，使用可信数据集估计噪声转移矩阵。 (图片来源: [Hendrycks et al. 2018](https://arxiv.org/abs/1802.05300))'
- en: If the trusted training dataset $\mathcal{D}_c$ gets large, we can train a neural
    network only on clean data and *distill* its knowledge into the primary model
    (i.e. the final model to make predictions at test time) using corrected **pseudo
    labels** ([Li et al. 2017](https://arxiv.org/abs/1703.02391)). The primary model
    is trained on the entire dataset, $\mathcal{D} = \mathcal{D}_c \cup \mathcal{D}_n$.
    Optionally the “side” information of label relations in the knowledge graph, if
    available, can be incorporated into distillation to help the robustness of the
    predictions of the network that is trained on limited data.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可信的训练数据集 $\mathcal{D}_c$ 变大，我们可以仅在干净数据上训练一个神经网络，并将其知识*提炼*到主模型（即在测试时进行预测的最终模型）中，使用校正的**伪标签**
    ([Li et al. 2017](https://arxiv.org/abs/1703.02391))。主模型在整个数据集 $\mathcal{D} =
    \mathcal{D}_c \cup \mathcal{D}_n$ 上进行训练。可选地，如果可用，可以将知识图中标签关系的“侧”信息合并到提炼中，以帮助训练在有限数据上的网络的预测的鲁棒性。
- en: 'The label correction distillation works as following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 标签校正提炼的工作如下：
- en: First train an auxiliary model $f_c$ from the small clean dataset $\mathcal{D}_c$
    to provide a soft label for each sample $x_i$, $s_i = \delta(f_c(\mathbf{x}_i)/T)$
    is the sigmoid activation with temperature $T$.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先从小的干净数据集 $\mathcal{D}_c$ 训练一个辅助模型 $f_c$，为每个样本 $x_i$ 提供一个软标签，$s_i = \delta(f_c(\mathbf{x}_i)/T)$
    是具有温度 $T$ 的 Sigmoid 激活。
- en: Because the clean dataset is not large, $f_c$ is likely to overfit, [Li et al.
    (2017)](https://arxiv.org/abs/1703.02391) turn to a knowledge graph $\mathcal{G}$
    that defines the relations in the label space and *propagate* the prediction among
    labels accordingly. The new soft label is donated as $\hat{s}_i = \mathcal{G}(s_i)$.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于干净数据集不大，$f_c$ 很可能会过拟合，[Li et al. (2017)](https://arxiv.org/abs/1703.02391)
    转向一个定义标签空间关系并根据此在标签之间*传播*预测的知识图 $\mathcal{G$。新的软标签表示为 $\hat{s}_i = \mathcal{G}(s_i)$。
- en: The primary model $f$ is trained with predictions from $f_c$ to imitate,
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主模型 $f$ 是通过从 $f_c$ 的预测进行训练以模仿的，
- en: $$ \mathcal{L}(y_i, f(\mathbf{x}_i)) = \text{CE}(\underbrace{\lambda y_i + (1
    - \lambda) \hat{s}_i}_\text{pseudo label}, f(\mathbf{x}_i)) $$
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \mathcal{L}(y_i, f(\mathbf{x}_i)) = \text{CE}(\underbrace{\lambda y_i + (1
    - \lambda) \hat{s}_i}_\text{伪标签}, f(\mathbf{x}_i)) $$
- en: Sample Reweighting and Selection
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样本重新加权和选择
- en: Some samples may be more likely to have inaccurate labels than others. Such
    estimation gives us intuition on which samples should be weighted less or more
    in the loss function. However, considering two types of biases in training data,
    class imbalance and noisy labels, there is actually a contradictory preference
    — We would prefer samples with larger loss to balance the label distribution but
    those with smaller loss for mitigating the potential noise. Some work ([Ren et
    al. 2018](https://arxiv.org/abs/1803.09050)) thus argue that in order to learn
    general forms of training data biases, it is *necessary* to have *a small unbiased
    validation* to guide training. The sample reweighting methods presented in this
    section all assume access to a small trusted set of clean data.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一些样本可能更有可能具有不准确的标签。这种估计让我们直观地知道哪些样本在损失函数中应该被赋予更少或更多的权重。然而，考虑到训练数据中的两种偏差，类别不平衡和嘈杂标签，实际上存在矛盾的偏好
    — 我们希望损失更大的样本来平衡标签分布，但那些损失较小的样本可以减轻潜在的噪声。一些研究（[Ren等人，2018](https://arxiv.org/abs/1803.09050)）因此认为，为了学习训练数据偏差的一般形式，有*必要*拥有*一个小而无偏的验证集*来指导训练。本节介绍的样本重新加权方法都假设可以访问一小部分可信的干净数据。
- en: 'Considering a binary classification task with random classification noise,
    $y, \hat{y} \in \{-1, +1\}$, the label flipping probabilities, $\rho_{-1}, \rho_{+1}
    \in [0, 0.5)$, are defined as:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个具有随机分类噪声的二元分类任务，$y, \hat{y} \in \{-1, +1\}$，标签翻转概率，$\rho_{-1}, \rho_{+1}
    \in [0, 0.5)$，定义如下：
- en: $$ \rho_{-1} = P(\tilde{y} = +1 \vert y=-1)\quad\rho_{+1} = P(\tilde{y}=-1 \vert
    y =+1) $$
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \rho_{-1} = P(\tilde{y} = +1 \vert y=-1)\quad\rho_{+1} = P(\tilde{y}=-1 \vert
    y =+1) $$
- en: '[Liu & Tao (2015)](https://arxiv.org/abs/1411.7718) applies **importance reweighting**
    to adjust the weighted distribution of observed $\hat{y}$ to match the distribution
    of unobservable $y$. Let $\mathcal{D}$ be the true data distribution and $\mathcal{D}_\rho$
    be the corrupted version.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[Liu & Tao (2015)](https://arxiv.org/abs/1411.7718)应用**重要性重新加权**来调整观察到的$\hat{y}$的加权分布，以匹配不可观测的$y$的分布。设$\mathcal{D}$为真实数据分布，$\mathcal{D}_\rho$为损坏版本。'
- en: $$ \begin{aligned} \mathcal{L}_{\ell,\mathcal{D}}(f) &= \mathbb{E}_{(\mathbf{x},y)\sim
    \mathcal{D}}[\ell(f(\mathbf{x}), y)] \\ &= \mathbb{E}_{(\mathbf{x},\tilde{y})\sim
    \mathcal{D}_\rho} \Big[ \frac{P_\mathcal{D}(\mathbf{x}, y=\tilde{y})}{P_{\mathcal{D}_\rho}(\mathbf{x},
    \tilde{y})} \ell(f(\mathbf{x}), \tilde{y}) \Big] \\ &= \mathbb{E}_{(\mathbf{x},\tilde{y})\sim
    \mathcal{D}_\rho} \Big[ \frac{P_\mathcal{D}(y=\tilde{y} \vert \mathbf{x})}{P_{\mathcal{D}_\rho}(\tilde{y}
    \vert \mathbf{x})} \ell(f(\mathbf{x}), \tilde{y}) \Big] & \text{; because }P_\mathcal{D}(\mathbf{x})=P_{\mathcal{D}_\rho}(\mathbf{x})
    \\ &= \mathbb{E}_{(\mathbf{x},\tilde{y})\sim \mathcal{D}_\rho} [ w(\mathbf{x},
    \hat{y})\ell(f(\mathbf{x}), \tilde{y}) ] = \mathcal{L}_{w\ell,\mathcal{D}}(f)
    \end{aligned} $$
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \begin{aligned} \mathcal{L}_{\ell,\mathcal{D}}(f) &= \mathbb{E}_{(\mathbf{x},y)\sim
    \mathcal{D}}[\ell(f(\mathbf{x}), y)] \\ &= \mathbb{E}_{(\mathbf{x},\tilde{y})\sim
    \mathcal{D}_\rho} \Big[ \frac{P_\mathcal{D}(\mathbf{x}, y=\tilde{y})}{P_{\mathcal{D}_\rho}(\mathbf{x},
    \tilde{y})} \ell(f(\mathbf{x}), \tilde{y}) \Big] \\ &= \mathbb{E}_{(\mathbf{x},\tilde{y})\sim
    \mathcal{D}_\rho} \Big[ \frac{P_\mathcal{D}(y=\tilde{y} \vert \mathbf{x})}{P_{\mathcal{D}_\rho}(\tilde{y}
    \vert \mathbf{x})} \ell(f(\mathbf{x}), \tilde{y}) \Big] & \text{; 因为 }P_\mathcal{D}(\mathbf{x})=P_{\mathcal{D}_\rho}(\mathbf{x})
    \\ &= \mathbb{E}_{(\mathbf{x},\tilde{y})\sim \mathcal{D}_\rho} [ w(\mathbf{x},
    \hat{y})\ell(f(\mathbf{x}), \tilde{y}) ] = \mathcal{L}_{w\ell,\mathcal{D}}(f)
    \end{aligned} $$
- en: Because,
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 因为，
- en: $$ \begin{aligned} P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x}) &= P_\mathcal{D}(y
    = \tilde{y} \vert \mathbf{x}) P_{\mathcal{D}_\rho}(\tilde{y} \vert y=\tilde{y})
    + P_\mathcal{D}(y = - \tilde{y} \vert \mathbf{x}) P_{\mathcal{D}_\rho}(\tilde{y}
    \vert y = - \tilde{y}) \\ &= P_\mathcal{D}(y = \tilde{y} \vert \mathbf{x}) (1
    - P_{\mathcal{D}_\rho}(- \tilde{y} \vert y=\tilde{y})) + (1 - P_\mathcal{D}(y
    = \tilde{y} \vert \mathbf{x})) P_{\mathcal{D}_\rho}(\tilde{y} \vert y = - \tilde{y})
    \\ &= P_\mathcal{D}(y = \tilde{y} \vert \mathbf{x}) (1 - \rho_{\tilde{y}}) + (1
    - P_\mathcal{D}(y = \tilde{y} \vert \mathbf{x})) \rho_{-\tilde{y}} \\ &= P_\mathcal{D}(y
    = \tilde{y} \vert \mathbf{x})(1 - \rho_{\tilde{y}} - \rho_{-\tilde{y}}) + \rho_{-\tilde{y}}
    \end{aligned} $$
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \begin{aligned} P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x}) &= P_\mathcal{D}(y
    = \tilde{y} \vert \mathbf{x}) P_{\mathcal{D}_\rho}(\tilde{y} \vert y=\tilde{y})
    + P_\mathcal{D}(y = - \tilde{y} \vert \mathbf{x}) P_{\mathcal{D}_\rho}(\tilde{y}
    \vert y = - \tilde{y}) \\ &= P_\mathcal{D}(y = \tilde{y} \vert \mathbf{x}) (1
    - P_{\mathcal{D}_\rho}(- \tilde{y} \vert y=\tilde{y})) + (1 - P_\mathcal{D}(y
    = \tilde{y} \vert \mathbf{x})) P_{\mathcal{D}_\rho}(\tilde{y} \vert y = - \tilde{y})
    \\ &= P_\mathcal{D}(y = \tilde{y} \vert \mathbf{x}) (1 - \rho_{\tilde{y}}) + (1
    - P_\mathcal{D}(y = \tilde{y} \vert \mathbf{x})) \rho_{-\tilde{y}} \\ &= P_\mathcal{D}(y
    = \tilde{y} \vert \mathbf{x})(1 - \rho_{\tilde{y}} - \rho_{-\tilde{y}}) + \rho_{-\tilde{y}}
    \end{aligned} $$
- en: Thus the weight assigned to a noisy sample is,
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，给嘈杂样本分配的权重为，
- en: $$ w(x, \tilde{y}) = \frac{P_\mathcal{D}(y=\tilde{y} \vert \mathbf{x})}{P_{\mathcal{D}_\rho}(\tilde{y}
    \vert \mathbf{x})} = \frac{P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x}) -
    \rho_{-\tilde{y}}}{(1-\rho_0-\rho_1) P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x})}
    $$
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: $$ w(x, \tilde{y}) = \frac{P_\mathcal{D}(y=\tilde{y} \vert \mathbf{x})}{P_{\mathcal{D}_\rho}(\tilde{y}
    \vert \mathbf{x})} = \frac{P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x}) -
    \rho_{-\tilde{y}}}{(1-\rho_0-\rho_1) P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x})}
    $$
- en: where $P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x})$ can be estimated using
    a simple logistic regression, but estimating the note rates is more challenging.
    Naive cross-validation can work out but is costly as the quality depends on the
    amount of trusted labels available. The paper approximates the upper bounds for
    noise rates first, $\rho_\tilde{y} \leq P_{\mathcal{D}_\rho}(- \tilde{y} \vert
    \mathbf{x})$ and then use a mild assumption to efficiently estimate them, $\hat{\rho}_{\tilde{y}}
    = \min_{\mathbf{x} \in {\mathbf{x}_1, \dots, \mathbf{x}_n}} \hat{P}_{\mathcal{D}_\rho}(-
    \tilde{y} \vert \mathbf{x})$. In their experiments, the advantage of importance
    reweighting only varies across datasets and is more beneficial when the noise
    rates are high in general.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $P_{\mathcal{D}_\rho}(\tilde{y} \vert \mathbf{x})$ 可以通过简单的逻辑回归进行估计，但估计音符率更具挑战性。天真的交叉验证可能行得通，但由于质量取决于可用的受信任标签数量，成本很高。该论文首先近似噪声率的上限，$\rho_\tilde{y}
    \leq P_{\mathcal{D}_\rho}(- \tilde{y} \vert \mathbf{x})$，然后使用温和的假设来高效地估计它们，$\hat{\rho}_{\tilde{y}}
    = \min_{\mathbf{x} \in {\mathbf{x}_1, \dots, \mathbf{x}_n}} \hat{P}_{\mathcal{D}_\rho}(-
    \tilde{y} \vert \mathbf{x})$。在他们的实验中，重要性重新加权的优势仅在数据集之间变化，并且在噪声率普遍较高时更为有益。
- en: Sample reweighting schemes can be learned by a separate network. *Learning to
    reweight* (**L2R**; [Ren et al. 2018](https://arxiv.org/abs/1803.09050)) is a
    meta-learning approach to directly optimize the weights in pursuit of best validation
    performance on a known set of clean data. Each example gets assigned with the
    weight based on its gradient direction. The weighted loss to minimize $\theta^*(\mathbf{w})$
    involves a set of training weights $\{w_i\}_{i=1}^n$ as unknown hyperparameters.
    These sample training weights $w_i$ are learned to minimize the loss on this unbiased
    validate set, $\mathcal{D}_c = \{x^\text{valid}_j\}_{j=1}^m$.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过一个单独的网络学习样本重新加权方案。 *学习重新加权* (**L2R**; [Ren et al. 2018](https://arxiv.org/abs/1803.09050))
    是一种元学习方法，直接优化权重以追求已知一组干净数据上的最佳验证性能。每个示例根据其梯度方向被分配权重。 用于最小化 $\theta^*(\mathbf{w})$
    的加权损失涉及一组训练权重 $\{w_i\}_{i=1}^n$ 作为未知超参数。 这些样本训练权重 $w_i$ 被学习以最小化在这个无偏验证集上的损失，$\mathcal{D}_c
    = \{x^\text{valid}_j\}_{j=1}^m$。
- en: $$ \begin{aligned} \theta^{*}(\mathbf{w}) &= \arg\min_\theta \sum_{i=1}^n w_i
    f(x_i; \theta) \\ \text{where optimal }\mathbf{w}^{*} &= \arg\min_{\mathbf{w},
    \mathbf{w} \geq \mathbf{0}} \frac{1}{m} \sum_{j=1}^m f(\mathbf{x}^\text{valid}_j;
    \theta^{*}(\mathbf{w})) \end{aligned} $$
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \begin{aligned} \theta^{*}(\mathbf{w}) &= \arg\min_\theta \sum_{i=1}^n w_i
    f(x_i; \theta) \\ \text{其中最优 }\mathbf{w}^{*} &= \arg\min_{\mathbf{w}, \mathbf{w}
    \geq \mathbf{0}} \frac{1}{m} \sum_{j=1}^m f(\mathbf{x}^\text{valid}_j; \theta^{*}(\mathbf{w}))
    \end{aligned} $$
- en: The learning process involves two nested loops of optimization, so pretty expensive,
    3x training time.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 学习过程涉及两个嵌套的优化循环，因此非常昂贵，训练时间增加 3 倍。
- en: '![](../Images/8ab31462fed4d475231e45637a0777c4.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ab31462fed4d475231e45637a0777c4.png)'
- en: 'Fig. 12\. Illustration of updates implemented by second order [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).
    (Image source: [Ren et al. 2018](https://arxiv.org/abs/1803.09050))'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '图 12\. 展示了第二阶[自动微分](https://en.wikipedia.org/wiki/Automatic_differentiation)实现的更新。
    (图片来源: [Ren et al. 2018](https://arxiv.org/abs/1803.09050))'
- en: They ran experiments on (1) two-class MNIST to test the robustness of L2R when
    the class distribution is imbalanced and (2) CIFAR-10 with noisy labels. L2R is
    shown to be better than other baseline methods at the time on both tasks.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 他们在 (1) 两类 MNIST 上进行实验，以测试 L2R 在类分布不平衡时的鲁棒性，以及 (2) 具有嘈杂标签的 CIFAR-10 上。 L2R 在两个任务上都表现出比当时其他基线方法更好的效果。
- en: '![](../Images/66275b6b04309719cb019b9077d4b7ea.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66275b6b04309719cb019b9077d4b7ea.png)'
- en: 'Fig. 13\. Left: Imbalanced classes on MNIST (class 4 and 9); Right: Effect
    of the number of clean samples. Task is on CIFAR-10 with 40% of data flipped to
    label 3\. (Image source: [Ren et al. 2018](https://arxiv.org/abs/1803.09050))'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '图 13\. 左: MNIST 上的不平衡类（类 4 和 9）；右: 清洁样本数量的影响。任务是在 CIFAR-10 上，40% 的数据翻转为标签 3\.
    (图片来源: [Ren et al. 2018](https://arxiv.org/abs/1803.09050))'
- en: '**MentorNet** ([Jiang et al. 2018](https://arxiv.org/abs/1712.05055)) uses
    teach-student curriculum learning to weight data. It incorporates two different
    networks, a mentor and a student. The mentor network provides a data-driven curriculum
    (i.e. sample training weighting scheme) for the student to focus on learning likely
    correct labels.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**MentorNet** ([Jiang et al. 2018](https://arxiv.org/abs/1712.05055)) 使用教师-学生课程学习来加权数据。它包含两个不同的网络，一个是导师，一个是学生。导师网络为学生提供了一个数据驱动的课程（即样本训练加权方案），让学生专注于学习可能是正确标签的内容。'
- en: 'Let $g_\psi$ be the MentorNet parameterized by $\psi$ , $f_\theta$ be the StudentNet
    parametrized by $\theta$ and $G$ be a predefined curriculum parameterized by $\lambda$.
    Given the training data $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^n$ for a
    $k$-class classification task, the MentorNet needs to predict a time-varying latent
    weight variable $\mathbf{w} \in [0, 1]^{n \times k}$ to guide the learning of
    StudentNet, taking an intermediate feature processed by StudentNet $f$ , $\mathbf{z}_i
    = \phi_{f_\theta}(\mathbf{x}_i, y_i)$:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让 $g_\psi$ 为由 $\psi$ 参数化的MentorNet，$f_\theta$ 为由 $\theta$ 参数化的StudentNet，$G$
    为由 $\lambda$ 参数化的预定义课程。给定用于$k$类分类任务的训练数据 $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^n$，MentorNet
    需要预测一个随时间变化的潜在权重变量 $\mathbf{w} \in [0, 1]^{n \times k}$ 来引导StudentNet的学习，取学生网络处理的中间特征
    $\mathbf{z}_i = \phi_{f_\theta}(\mathbf{x}_i, y_i)$：
- en: $$ g_{\psi^{*}}(\mathbf{z}_i) = \arg\min_{w_i \in [0,1]} \mathcal{L}(\theta,
    \mathbf{w}), \forall i \in [1, n] $$
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: $$ g_{\psi^{*}}(\mathbf{z}_i) = \arg\min_{w_i \in [0,1]} \mathcal{L}(\theta,
    \mathbf{w}), \forall i \in [1, n] $$
- en: StudentNet learns to minimize the following learning objective,
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: StudentNet 学习最小化以下学习目标，
- en: $$ \begin{aligned} \mathcal{L}(\theta, \mathbf{w}) &= \frac{1}{n}\sum_{i=1}^n
    \mathbf{w}_i^\top \ell(y_i, f_\theta(\mathbf{x}_i)) + G_\lambda(\mathbf{w}) +
    \alpha |\theta|^2_2 \\ &= \frac{1}{n}\sum_{i=1}^n g_\psi(\mathbf{z}_i)^\top \ell_i
    + G_\lambda(\mathbf{w}) + \alpha |\theta|^2_2 & \text{; Let }\ell_i = \ell(y_i,
    f_\theta(\mathbf{x}_i)) \\ \end{aligned} $$
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \begin{aligned} \mathcal{L}(\theta, \mathbf{w}) &= \frac{1}{n}\sum_{i=1}^n
    \mathbf{w}_i^\top \ell(y_i, f_\theta(\mathbf{x}_i)) + G_\lambda(\mathbf{w}) +
    \alpha |\theta|^2_2 \\ &= \frac{1}{n}\sum_{i=1}^n g_\psi(\mathbf{z}_i)^\top \ell_i
    + G_\lambda(\mathbf{w}) + \alpha |\theta|^2_2 & \text{; 让 }\ell_i = \ell(y_i,
    f_\theta(\mathbf{x}_i)) \\ \end{aligned} $$
- en: The mentor network $g_\psi$ is trained with cross entropy on the input $(\phi_{f_\theta}(\mathbf{x}_i,
    y_i), w^{*}_i)$ , where $v^*_i=1$ if $y_i$ is known to be a correct label, otherwise
    0\. The architecture of MentorNet does not have to be very complicated. In the
    paper, they adopted a LSTM layer to capture the prediction variance in time.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 导师网络 $g_\psi$ 在输入 $(\phi_{f_\theta}(\mathbf{x}_i, y_i), w^{*}_i)$ 上通过交叉熵进行训练，其中如果
    $y_i$ 已知是正确标签，则 $v^*_i=1$，否则为0。MentorNet的架构不必非常复杂。在论文中，他们采用了一个LSTM层来捕捉时间上的预测方差。
- en: '![](../Images/acca016bcbecd43a5b5cbc29d1f6ff68.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acca016bcbecd43a5b5cbc29d1f6ff68.png)'
- en: 'Fig. 14\. Model architecture of MentorNet and StudentNet which are trained
    simultaneously, where MentorNet predicts the sample weights for StudentNet to
    train on. (Image source: [Jiang et al. 2018](https://arxiv.org/abs/1712.05055))'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图14。MentorNet和StudentNet的模型架构同时训练，其中MentorNet预测学生网络的样本权重以进行训练。（图片来源：[Jiang et
    al. 2018](https://arxiv.org/abs/1712.05055)）
- en: 'Different from MentorNet where one network explicitly learns weighting scheme
    and curriculum for the other network, **Co-teaching** ([Han et al. 2018](https://arxiv.org/abs/1804.06872))
    trains two neural networks, $f_1$ and $f_2$, simultaneously and lets them teach
    each other by feeding data to each other selectively. Co-teaching consists of
    three steps:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与MentorNet不同的是，其中一个网络明确学习另一个网络的加权方案和课程，**Co-teaching** ([Han et al. 2018](https://arxiv.org/abs/1804.06872))
    同时训练两个神经网络，$f_1$ 和 $f_2$，让它们通过有选择地向彼此提供数据来互相教导。Co-teaching 包括三个步骤：
- en: First, each network feeds forward the current mini-batch and selects samples
    with potentially clean labels;
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，每个网络前馈当前小批量数据并选择可能具有干净标签的样本；
- en: Then two networks exchange information on which samples in the batch should
    be used for training. Small-loss instances are selected as they are more likely
    to be associated with correct labels. The percentage of the batch to select is
    determined by a time-dependent function $R(T)$. The value of $R(T)$ decreases
    in time because the network is more likely to overfit and memorize noisy labels
    as training progresses and thus we use a smaller sampling percentage to keep the
    selected data quality high.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，两个网络交换信息，确定批次中应该用于训练的样本。选择小损失实例，因为它们更有可能与正确标签相关联。选择批次的百分比由时间相关函数$R(T)$确定。$R(T)$的值随时间减少，因为随着训练的进行，网络更有可能过拟合和记忆噪声标签，因此我们使用较小的采样百分比来保持所选数据的质量高。
- en: Finally, each network runs back-propagation updates with the data selected by
    its peer.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，每个网络都会通过其同行选择的数据运行反向传播更新。
- en: According to their experiments, co-teaching performs better than [F-correction](#fcorrection)
    where the noise rates are high or the corruption transition matrix is not symmetric.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 根据他们的实验，当噪声率较高或破坏转移矩阵不对称时，共同教学的表现优于[F-校正](#fcorrection)。
- en: '![](../Images/d2f5954362b9c73d8032b85a039da12f.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2f5954362b9c73d8032b85a039da12f.png)'
- en: 'Fig. 15\. Algorithm of co-teaching in which two networks are trained separately
    in parallel and each selects samples for the other to train on. (Image source:
    [Han et al. 2018](https://arxiv.org/abs/1804.06872))'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图15。共同教学算法，其中两个网络并行训练，每个网络选择另一个网络进行训练的样本。（图片来源：[韩等人 2018](https://arxiv.org/abs/1804.06872)）
- en: Citation
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引文
- en: 'Cited as:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 引用为：
- en: 'Weng, Lilian. (Apr 2022). Learning with not enough data part 3: data generation.
    Lil’Log. https://lilianweng.github.io/posts/2022-04-15-data-gen/.'
  id: totrans-188
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 翁，莉莉安。 (2022年4月)。数据不足学习第3部分：数据生成。Lil’Log。 [链接](https://lilianweng.github.io/posts/2022-04-15-data-gen/)。
- en: Or
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 或
- en: '[PRE0]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Reference
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Zhang et al. [“Adversarial AutoAgument”](https://arxiv.org/abs/1912.11188)
    ICLR 2020.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 张等人。“对抗自动增强” [ICLR 2020](https://arxiv.org/abs/1912.11188)。'
- en: '[2] Kumar et al. [“Data Augmentation using Pre-trained Transformer Models.”](https://arxiv.org/abs/2003.02245)
    AACL 2020 Workshop.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Kumar等人。“使用预训练转换器模型进行数据增强。” [AACL 2020 Workshop](https://arxiv.org/abs/2003.02245)。'
- en: '[3] Anaby-Tavor et al. [“Not enough data? Deep learning to rescue!”](https://arxiv.org/abs/1911.03118)
    AAAI 2020.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Anaby-Tavor等人。“数据不足？深度学习来拯救！” [AAAI 2020](https://arxiv.org/abs/1911.03118)。'
- en: '[4] Wang et al. [“Want To Reduce Labeling Cost? GPT-3 Can Help.”](https://arxiv.org/abs/2108.13487)
    EMNLP 2021.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] 王等人。“想要减少标注成本？GPT-3可以帮助。” [EMNLP 2021](https://arxiv.org/abs/2108.13487)。'
- en: '[5] Wang et al. [“Towards Zero-Label Language Learning.”](https://arxiv.org/abs/2109.09193)
    arXiv preprint arXiv:2109.09193 (2021).'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] 王等人。“走向零标签语言学习。” [arXiv:2109.09193](https://arxiv.org/abs/2109.09193) arXiv预印本
    arXiv:2109.09193 (2021)。'
- en: '[6] Schick & Schutze. [Generating Datasets with Pretrained Language Models."](https://arxiv.org/abs/2104.07540)
    EMNLP 2021.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Schick & Schutze。“使用预训练语言模型生成数据集。” [EMNLP 2021](https://arxiv.org/abs/2104.07540)。'
- en: '[7] Han et al. [“Unsupervised Neural Machine Translation with Generative Language
    Models Only.”](https://arxiv.org/abs/2110.05448) arXiv preprint arXiv:2110.05448
    (2021).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] 韩等人。“仅使用生成语言模型进行无监督神经机器翻译。” [arXiv:2110.05448](https://arxiv.org/abs/2110.05448)
    arXiv预印本 arXiv:2110.05448 (2021)。'
- en: '[8] Guo et al. [“Augmenting data with mixup for sentence classification: An
    empirical study.”](https://arxiv.org/abs/1905.08941) arXiv preprint arXiv:1905.08941
    (2019).'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] 郭等人。“使用mixup增强数据进行句子分类：一项实证研究。” [arXiv:1905.08941](https://arxiv.org/abs/1905.08941)
    arXiv预印本 arXiv:1905.08941 (2019)。'
- en: '[9] Ekin D. Cubuk et al. [“AutoAugment: Learning augmentation policies from
    data.”](https://arxiv.org/abs/1805.09501) arXiv preprint arXiv:1805.09501 (2018).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Ekin D. Cubuk等人。“AutoAugment：从数据中学习增强策略。” [arXiv:1805.09501](https://arxiv.org/abs/1805.09501)
    arXiv预印本 arXiv:1805.09501 (2018)。'
- en: '[10] Daniel Ho et al. [“Population Based Augmentation: Efficient Learning of
    Augmentation Policy Schedules.”](https://arxiv.org/abs/1905.05393) ICML 2019.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Daniel Ho等人。“基于人口的增强：有效学习增强策略计划。” [ICML 2019](https://arxiv.org/abs/1905.05393)。'
- en: '[11] Cubuk & Zoph et al. [“RandAugment: Practical automated data augmentation
    with a reduced search space.”](https://arxiv.org/abs/1909.13719) arXiv preprint
    arXiv:1909.13719 (2019).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] Cubuk & Zoph等人。“RandAugment：具有减少搜索空间的实用自动化数据增强。” [arXiv:1909.13719](https://arxiv.org/abs/1909.13719)
    arXiv预印本 arXiv:1909.13719 (2019)。'
- en: '[12] Zhang et al. [“mixup: Beyond Empirical Risk Minimization.”](https://arxiv.org/abs/1710.09412)
    ICLR 2017.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] 张等人。“混合：超越经验风险最小化。” [ICLR 2017](https://arxiv.org/abs/1710.09412)。'
- en: '[13] Yun et al. [“CutMix: Regularization Strategy to Train Strong Classifiers
    with Localizable Features.”](https://arxiv.org/abs/1905.04899) ICCV 2019.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] 云等. [“CutMix：训练具有可定位特征的强分类器的正则化策略。”](https://arxiv.org/abs/1905.04899)
    ICCV 2019.'
- en: '[14] Kalantidis et al. [“Mixing of Contrastive Hard Negatives”](https://arxiv.org/abs/2010.01028)
    NeuriPS 2020.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] 卡兰蒂迪斯等. [“对比硬负例的混合”](https://arxiv.org/abs/2010.01028) NeuriPS 2020.'
- en: '[15] Wei & Zou. [“EDA: Easy data augmentation techniques for boosting performance
    on text classification tasks.”](https://arxiv.org/abs/1901.11196) EMNLP-IJCNLP
    2019.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[15] 魏 & 邹. [“EDA：用于提升文本分类任务性能的简易数据增强技术。”](https://arxiv.org/abs/1901.11196)
    EMNLP-IJCNLP 2019.'
- en: '[16] Kobayashi. [“Contextual Augmentation: Data Augmentation by Words with
    Paradigmatic Relations.”](https://arxiv.org/abs/1805.06201) NAACL 2018'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[16] 小林. [“上下文增强：通过具有范例关系的词进行数据增强。”](https://arxiv.org/abs/1805.06201) NAACL
    2018'
- en: '[17] Fang et al. [“CERT: Contrastive self-supervised learning for language
    understanding.”](https://arxiv.org/abs/2005.12766) arXiv preprint arXiv:2005.12766
    (2020).'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[17] 方等. [“CERT：用于语言理解的对比自监督学习。”](https://arxiv.org/abs/2005.12766) arXiv预印本
    arXiv:2005.12766 (2020).'
- en: '[18] Gao et al. [“SimCSE: Simple Contrastive Learning of Sentence Embeddings.”](https://arxiv.org/abs/2104.08821)
    arXiv preprint arXiv:2104.08821 (2020). [[code](https://github.com/princeton-nlp/SimCSE)]'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[18] 高等. [“SimCSE：简单的对比学习句子嵌入。”](https://arxiv.org/abs/2104.08821) arXiv预印本
    arXiv:2104.08821 (2020). [[code](https://github.com/princeton-nlp/SimCSE)]'
- en: '[19] Shen et al. [“A Simple but Tough-to-Beat Data Augmentation Approach for
    Natural Language Understanding and Generation.”](https://arxiv.org/abs/2009.13818)
    arXiv preprint arXiv:2009.13818 (2020) [[code](https://github.com/dinghanshen/cutoff)]'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[19] 沈等. [“一种简单但难以超越的自然语言理解和生成数据增强方法。”](https://arxiv.org/abs/2009.13818) arXiv预印本
    arXiv:2009.13818 (2020) [[code](https://github.com/dinghanshen/cutoff)]'
- en: '[20] Wang & van den Oord. [“Multi-Format Contrastive Learning of Audio Representations.”](https://arxiv.org/abs/2103.06508)
    NeuriPS Workshop 2020.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[20] 王 & van den Oord. [“音频表示的多格式对比学习。”](https://arxiv.org/abs/2103.06508)
    NeuriPS Workshop 2020.'
- en: '[21] Wu et al. [“Conditional BERT Contextual Augmentation”](https://arxiv.org/abs/1812.06705)
    arXiv preprint arXiv:1812.06705 (2018).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[21] 吴等. [“条件BERT上下文增强”](https://arxiv.org/abs/1812.06705) arXiv预印本 arXiv:1812.06705
    (2018).'
- en: '[22 Zhu et al. [“FreeLB: Enhanced Adversarial Training for Natural Language
    Understanding.”](https://arxiv.org/abs/1909.11764) ICLR 2020.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[22] 朱等. [“FreeLB：增强的自然语言理解对抗训练。”](https://arxiv.org/abs/1909.11764) ICLR 2020.'
- en: '[23] Affinity and Diversity: Quantifying Mechanisms of Data Augmentation Gontijo-Lopes
    et al. 2020 ([https://arxiv.org/abs/2002.08973](https://arxiv.org/abs/2002.08973))'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[23] 亲和性和多样性：量化数据增强机制 Gontijo-Lopes等. 2020 ([https://arxiv.org/abs/2002.08973](https://arxiv.org/abs/2002.08973))'
- en: '[24] Song et al. [“Learning from Noisy Labels with Deep Neural Networks: A
    Survey.”](https://arxiv.org/abs/2007.08199) TNNLS 2020.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[24] 宋等. [“使用深度神经网络学习带有噪声标签：一项调查。”](https://arxiv.org/abs/2007.08199) TNNLS
    2020.'
- en: '[25] Zhang & Sabuncu. [“Generalized cross entropy loss for training deep neural
    networks with noisy labels.”](https://arxiv.org/abs/1805.07836) NeuriPS 2018.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[25] 张 & 萨邦库. [“用于训练带有噪声标签的深度神经网络的广义交叉熵损失。”](https://arxiv.org/abs/1805.07836)
    NeuriPS 2018.'
- en: '[26] Goldberger & Ben-Reuven. [“Training deep neural-networks using a noise
    adaptation layer.”](https://openreview.net/forum?id=H12GRgcxg) ICLR 2017.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[26] 戈德伯格 & 本-鲁文. [“使用噪声适应层训练深度神经网络。”](https://openreview.net/forum?id=H12GRgcxg)
    ICLR 2017.'
- en: '[27] Sukhbaatar et al. [“Training convolutional networks with noisy labels.”](https://arxiv.org/abs/1406.2080)
    ICLR Workshop 2015.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[27] 苏克巴塔尔等. [“用噪声标签训练卷积网络。”](https://arxiv.org/abs/1406.2080) ICLR Workshop
    2015.'
- en: '[28] Patrini et al. [“Making Deep Neural Networks Robust to Label Noise: a
    Loss Correction Approach”](https://arxiv.org/abs/1609.03683) CVPR 2017.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[28] 帕特里尼等. [“使深度神经网络对标签噪声具有鲁棒性：一种损失校正方法”](https://arxiv.org/abs/1609.03683)
    CVPR 2017.'
- en: '[29] Hendrycks et al. [“Using trusted data to train deep networks on labels
    corrupted by severe noise.”](https://arxiv.org/abs/1802.05300) NeuriPS 2018.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[29] 亨德里克斯等. [“使用可信数据训练受严重噪声污染标签的深度网络。”](https://arxiv.org/abs/1802.05300)
    NeuriPS 2018.'
- en: '[30] Zhang & Sabuncu. [“Generalized cross entropy loss for training deep neural
    networks with noisy labels.”](https://arxiv.org/abs/1805.07836) NeuriPS 2018.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[30] 张 & 萨邦库. [“用于训练带有噪声标签的深度神经网络的广义交叉熵损失。”](https://arxiv.org/abs/1805.07836)
    NeuriPS 2018.'
- en: '[31] Lyu & Tsang. [“Curriculum loss: Robust learning and generalization against
    label corruption.”](https://arxiv.org/abs/1905.10045) ICLR 2020.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[31] 吕 & 曾. [“课程损失：针对标签污染的稳健学习和泛化。”](https://arxiv.org/abs/1905.10045) ICLR
    2020.'
- en: '[32] Han et al. [“Co-teaching: Robust training of deep neural networks with
    extremely noisy labels.”](https://arxiv.org/abs/1804.06872) NeuriPS 2018\. ([code](https://github.com/bhanML/Co-teaching))'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[32] 韩等人。[“共同教学：在极其嘈杂的标签下训练深度神经网络。”](https://arxiv.org/abs/1804.06872) NeuriPS
    2018\. ([code](https://github.com/bhanML/Co-teaching))'
- en: '[33] Ren et al. [“Learning to reweight examples for robust deep learning.”](https://arxiv.org/abs/1803.09050)
    ICML 2018.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[33] 任等人。[“学习为强大深度学习重新加权示例。”](https://arxiv.org/abs/1803.09050) ICML 2018.'
- en: '[34] Jiang et al. [“MentorNet: Learning data-driven curriculum for very deep
    neural networks on corrupted labels.”](https://arxiv.org/abs/1712.05055) ICML
    2018.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[34] 姜等人。[“MentorNet：学习基于数据的课程设计用于受损标签的深度神经网络。”](https://arxiv.org/abs/1712.05055)
    ICML 2018.'
- en: '[35] Li et al. [“Learning from noisy labels with distillation.”](https://arxiv.org/abs/1703.02391)
    ICCV 2017.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[35] 李等人。[“通过蒸馏学习从带有噪声标签中学习。”](https://arxiv.org/abs/1703.02391) ICCV 2017.'
- en: '[36] Liu & Tao. [“Classification with noisy labels by importance reweighting.”](https://arxiv.org/abs/1411.7718)
    TPAMI 2015.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '[36] 刘 & 陶。[“通过重要性重新加权处理带有噪声标签的分类问题。”](https://arxiv.org/abs/1411.7718) TPAMI
    2015.'
- en: '[37] Ghosh, et al. [“Robust loss functions under label noise for deep neural
    networks.”](https://arxiv.org/abs/1712.09482) AAAI 2017.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[37] 高仕等人。[“针对深度神经网络标签噪声的鲁棒损失函数。”](https://arxiv.org/abs/1712.09482) AAAI 2017.'
- en: '[38] Hu et al. [“Does Distributionally Robust Supervised Learning Give Robust
    Classifiers? “](https://arxiv.org/abs/1611.02041) ICML 2018.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[38] 胡等人。[“分布鲁棒监督学习是否提供鲁棒分类器？”](https://arxiv.org/abs/1611.02041) ICML 2018.'
- en: '* * *'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: $y=i$ is not a technically correct way to annotate a label being a certain value,
    since we usually use one-hot encoding (i.e. $\mathbf{y} = \mathbf{e}_i$). We use
    this form for simplicity. [↩︎](#fnref:1)
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $y=i$ 并不是一种技术上正确的注释标签为特定值的方式，因为我们通常使用独热编码（即 $\mathbf{y} = \mathbf{e}_i$）。我们出于简单起见使用这种形式。 [↩︎](#fnref:1)
